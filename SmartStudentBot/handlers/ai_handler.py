# handlers/ai_handler.py
# Ù‡Ù†Ø¯Ù„Ø± Ú©Ø§Ù…Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ - Ù†Ø³Ø®Ù‡ Û·.Û°
# Ú˜Ø§Ù†ÙˆÛŒÙ‡ Û²Û°Û²Ûµ

"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    ğŸ¤– Ù‡Ù†Ø¯Ù„Ø± Ù‡ÙˆØ´Ù…Ù†Ø¯ SmartStudentBot - Ù†Ø³Ø®Ù‡ Û·.Û°
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Ù†Ø³Ø®Ù‡ Û·.Û° Ø´Ø§Ù…Ù„:
    âœ… Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ú©Ø§Ù…Ù„ Ø§Ø² ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ù…Ú©Ø§Ù„Ù…Ù‡ (Ù…Ø´Ú©Ù„ Ø§ØµÙ„ÛŒ Ø­Ù„ Ø´Ø¯)
    âœ… Ø§Ù†ØªØ®Ø§Ø¨ Ùˆ Ø§Ø³ØªÙØ§Ø¯Ù‡ ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø² Ù…Ø¯Ù„ ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø±
    âœ… Ù¾ÛŒØ§Ù… ØµÙˆØªÛŒ Ø¨Ø§ OpenRouter (Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ OpenAI API)
    âœ… ØªØ­Ù„ÛŒÙ„ ØªØµÙˆÛŒØ± Ø¨Ø§ Vision API
    âœ… Ù†Ù…Ø§ÛŒØ´ ÙˆØ§Ø¶Ø­ Fallback Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø±
    âœ… Ø®ÙˆØ§Ù†Ø¯Ù† ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§Ø² config.py
    âœ… Ø³ÛŒØ³ØªÙ… Warm-up Ùˆ Keep-Alive
    âœ… Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ø§Ù…Ù„ Ø®Ø·Ø§Ù‡Ø§ Ø¨Ø§ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ø¶Ø­

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

from __future__ import annotations

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û±: Ø§ÛŒÙ…Ù¾ÙˆØ±Øªâ€ŒÙ‡Ø§
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯
import asyncio
import random
import traceback
import base64
import io
from datetime import datetime, timedelta
from collections import defaultdict, Counter, deque
from contextlib import suppress, asynccontextmanager
from dataclasses import dataclass, field
from typing import (
    Dict, List, Optional, Any, Tuple, Callable, 
    AsyncGenerator, TypeVar, Union
)
from enum import Enum

# Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ø´Ø®Øµ Ø«Ø§Ù„Ø«
import aiohttp
from aiogram import Router, F, Bot
from aiogram.types import Message, CallbackQuery
from aiogram.filters import Command, StateFilter
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton
from aiogram.enums import ParseMode, ChatAction
from aiogram.exceptions import TelegramBadRequest, TelegramNetworkError

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù¾Ø±ÙˆÚ˜Ù‡
from config import settings, logger


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û²: Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ø³Ø±ÙˆÛŒØ³â€ŒÙ‡Ø§ Ø¨Ø§ Fallback Ø§ÛŒÙ…Ù†
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Ø§ÛŒÙ…Ù¾ÙˆØ±Øª AI Service
try:
    from services.ai_service import (
        ai_service, 
        AVAILABLE_MODELS, 
        AIResponse,
        AIModel,
        CHAT_MODEL_PRIORITY,
        VISION_MODEL_PRIORITY,
        AUDIO_MODEL_PRIORITY,
    )
    AI_SERVICE_AVAILABLE = True
    logger.info("âœ… AI Service imported successfully")
except ImportError as e:
    logger.warning(f"âš ï¸ AI Service not available: {e}")
    AI_SERVICE_AVAILABLE = False
    ai_service = None
    AVAILABLE_MODELS = {}
    CHAT_MODEL_PRIORITY = []
    VISION_MODEL_PRIORITY = []
    AUDIO_MODEL_PRIORITY = []
    
    @dataclass
    class AIResponse:
        """Ú©Ù„Ø§Ø³ Fallback Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø® AI"""
        text: str = "Ø³Ø±ÙˆÛŒØ³ AI Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª."
        is_ai_generated: bool = False
        model_used: Optional[str] = None
        model_key: Optional[str] = None
        provider: Optional[str] = None
        processing_time_ms: int = 0
        from_cache: bool = False
        is_fallback: bool = True
        was_model_fallback: bool = False
        original_model: Optional[str] = None
        error: Optional[str] = None


# Ø§ÛŒÙ…Ù¾ÙˆØ±Øª ØªÙˆØ§Ø¨Ø¹ Ø²Ø¨Ø§Ù†
try:
    from handlers.cmd_start import get_user_lang, get_text, load_lang
    LANG_SERVICE_AVAILABLE = True
except ImportError:
    LANG_SERVICE_AVAILABLE = False
    def get_user_lang(user_id: int) -> dict: 
        return {"code": "fa"}
    def get_text(lang: dict, key: str, default: str = "") -> str: 
        return lang.get(key, default or key)
    def load_lang(code: str) -> dict: 
        return {"code": code}


# Ø§ÛŒÙ…Ù¾ÙˆØ±Øª Ø¯ÛŒØªØ§Ø¨ÛŒØ³
try:
    from database import db
    DATABASE_AVAILABLE = True
except ImportError:
    DATABASE_AVAILABLE = False
    db = None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û³: Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Router
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

router = Router()
router.name = "ai_handler"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û´: Ø®ÙˆØ§Ù†Ø¯Ù† ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§Ø² config.py
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Voice
VOICE_ENABLED: bool = settings.AI_VOICE_ENABLED
VOICE_MAX_DURATION_SECONDS: int = settings.AI_VOICE_MAX_DURATION
VOICE_SUPPORTED_FORMATS: List[str] = ["ogg", "mp3", "wav", "m4a", "oga", "webm"]

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Image
IMAGE_ENABLED: bool = settings.AI_IMAGE_ENABLED
IMAGE_MAX_SIZE_MB: int = settings.AI_IMAGE_MAX_SIZE_MB
IMAGE_SUPPORTED_FORMATS: List[str] = ["jpg", "jpeg", "png", "gif", "webp"]

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Rate Limiting
RATE_LIMIT_MESSAGES: int = settings.AI_RATE_LIMIT_MESSAGES
RATE_LIMIT_WINDOW: int = settings.AI_RATE_LIMIT_WINDOW
RATE_LIMIT_PREMIUM_MULTIPLIER: int = settings.AI_RATE_LIMIT_PREMIUM_MULTIPLIER

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú†Øª
MAX_CHAT_HISTORY: int = settings.AI_HISTORY_MAX_MESSAGES
HISTORY_ENABLED: bool = settings.AI_HISTORY_ENABLED
HISTORY_CLEANUP_INTERVAL: int = 3600  # Ù‡Ø± Ø³Ø§Ø¹Øª
HISTORY_MAX_AGE_HOURS: int = 24

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Timeout Ùˆ Retry
AI_TIMEOUT_SECONDS: int = settings.AI_TIMEOUT_SECONDS
AI_RETRY_ATTEMPTS: int = settings.AI_MAX_RETRIES
AI_RETRY_DELAY_BASE: float = 1.0
AI_RETRY_DELAY_MAX: float = 10.0
TYPING_INTERVAL: int = 4

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Warm-up Ùˆ Keep-Alive
WARMUP_ENABLED: bool = settings.AI_WARMUP_ENABLED
WARMUP_TIMEOUT_SECONDS: int = settings.AI_WARMUP_TIMEOUT
WARMUP_MESSAGE: str = "ping"
WARMUP_CACHE_DURATION: int = 300

KEEP_ALIVE_ENABLED: bool = settings.AI_KEEP_ALIVE_ENABLED
KEEP_ALIVE_INTERVAL: int = settings.AI_KEEP_ALIVE_INTERVAL
KEEP_ALIVE_MESSAGE: str = "keep-alive"

COLD_START_DETECTION_ENABLED: bool = True
COLD_START_THRESHOLD_MS: int = 5000
COLD_START_EXTRA_RETRIES: int = 2

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ú©Ø´
CACHE_ENABLED: bool = settings.AI_CACHE_ENABLED

# Ù…Ø¯Ù„ Ù¾ÛŒØ´â€ŒÙØ±Ø¶
DEFAULT_MODEL: str = settings.AI_DEFAULT_MODEL

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…ØªØ±ÛŒÚ©
METRICS_MAX_POPULAR_QUESTIONS: int = 100
METRICS_RESPONSE_TIME_SAMPLES: int = 100


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Ûµ: Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ Ø§Ù†ØªØ®Ø§Ø¨ ØªÙˆØ³Ø· Ú©Ø§Ø±Ø¨Ø±
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ Ù‡Ø± Ú©Ø§Ø±Ø¨Ø±
_user_model_preferences: Dict[int, str] = {}
_user_model_last_activity: Dict[int, datetime] = {}

# Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù†Ù…Ø§ÛŒØ´ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§
USER_SELECTABLE_MODELS: Dict[str, Dict[str, Any]] = {
    "gpt-4o-mini": {
        "icon": "âš¡",
        "name": "GPT-4o Mini",
        "description": "Ø³Ø±ÛŒØ¹ Ùˆ Ø§Ø±Ø²Ø§Ù† - Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ",
        "provider": "OpenAI",
        "supports_vision": True,
        "supports_audio": False,
    },
    "gpt-4o": {
        "icon": "ğŸ§ ",
        "name": "GPT-4o",
        "description": "Ù‚ÙˆÛŒâ€ŒØªØ±ÛŒÙ† - Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ù¾ÛŒÚ†ÛŒØ¯Ù‡",
        "provider": "OpenAI",
        "supports_vision": True,
        "supports_audio": True,
    },
    "claude-3.5-sonnet": {
        "icon": "ğŸ­",
        "name": "Claude 3.5 Sonnet",
        "description": "Ø¨Ø³ÛŒØ§Ø± Ù‡ÙˆØ´Ù…Ù†Ø¯ - Ú©Ø¯Ù†ÙˆÛŒØ³ÛŒ Ø¹Ø§Ù„ÛŒ",
        "provider": "Anthropic",
        "supports_vision": True,
        "supports_audio": False,
    },
    "claude-3-haiku": {
        "icon": "ğŸ‡",
        "name": "Claude 3 Haiku",
        "description": "Ø³Ø±ÛŒØ¹ Ùˆ Ø§Ø±Ø²Ø§Ù†",
        "provider": "Anthropic",
        "supports_vision": True,
        "supports_audio": False,
    },
    "gemini-flash": {
        "icon": "ğŸ’",
        "name": "Gemini Flash 1.5",
        "description": "Ú¯ÙˆÚ¯Ù„ - Ø³Ø±ÛŒØ¹ Ùˆ Ø±Ø§ÛŒÚ¯Ø§Ù†",
        "provider": "Google",
        "supports_vision": True,
        "supports_audio": True,
    },
    "gemini-pro": {
        "icon": "ğŸ’",
        "name": "Gemini Pro 1.5",
        "description": "Ú¯ÙˆÚ¯Ù„ - context Ø¨Ù„Ù†Ø¯",
        "provider": "Google",
        "supports_vision": True,
        "supports_audio": True,
    },
    "llama-3.1-70b": {
        "icon": "ğŸ¦™",
        "name": "Llama 3.1 70B",
        "description": "Ù…ØªØ§ - Ø±Ø§ÛŒÚ¯Ø§Ù† Ùˆ Ù‚ÙˆÛŒ",
        "provider": "Meta",
        "supports_vision": False,
        "supports_audio": False,
    },
    "llama-3.1-8b": {
        "icon": "ğŸ¦™",
        "name": "Llama 3.1 8B",
        "description": "Ù…ØªØ§ - Ø³Ø¨Ú© Ùˆ Ø³Ø±ÛŒØ¹",
        "provider": "Meta",
        "supports_vision": False,
        "supports_audio": False,
    },
    "grok": {
        "icon": "ğŸ¤–",
        "name": "Grok",
        "description": "Ø§ÛŒÙ„Ø§Ù† Ù…Ø§Ø³Ú© - xAI",
        "provider": "xAI",
        "supports_vision": False,
        "supports_audio": False,
    },
    "mistral-large": {
        "icon": "ğŸŒªï¸",
        "name": "Mistral Large",
        "description": "ÙØ±Ø§Ù†Ø³ÙˆÛŒ - Ù‚ÙˆÛŒ",
        "provider": "Mistral",
        "supports_vision": False,
        "supports_audio": False,
    },
}


def get_user_model(user_id: int) -> str:
    """Ø¯Ø±ÛŒØ§ÙØª Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ Ú©Ø§Ø±Ø¨Ø±"""
    return _user_model_preferences.get(user_id, DEFAULT_MODEL)


def set_user_model(user_id: int, model_key: str) -> bool:
    """ØªÙ†Ø¸ÛŒÙ… Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±"""
    if model_key in USER_SELECTABLE_MODELS or model_key in AVAILABLE_MODELS:
        _user_model_preferences[user_id] = model_key
        _user_model_last_activity[user_id] = datetime.now()
        logger.info(f"ğŸ¤– User {user_id} selected model: {model_key}")
        return True
    return False


def cleanup_user_model_preferences() -> int:
    """Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…Ø¯Ù„ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† ØºÛŒØ±ÙØ¹Ø§Ù„"""
    if not _user_model_last_activity:
        return 0
    
    cutoff = datetime.now() - timedelta(hours=HISTORY_MAX_AGE_HOURS)
    users_to_remove = [
        user_id for user_id, last_time in _user_model_last_activity.items()
        if last_time < cutoff
    ]
    
    for user_id in users_to_remove:
        _user_model_preferences.pop(user_id, None)
        _user_model_last_activity.pop(user_id, None)
    
    if users_to_remove:
        logger.info(f"ğŸ§¹ Cleaned {len(users_to_remove)} user model preferences")
    
    return len(users_to_remove)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û¶: Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class Language(Enum):
    """Ø²Ø¨Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø´Ø¯Ù‡"""
    FA = "fa"
    EN = "en"
    IT = "it"


@dataclass
class ServiceHealth:
    """ÙˆØ¶Ø¹ÛŒØª Ø³Ù„Ø§Ù…Øª Ø³Ø±ÙˆÛŒØ³"""
    is_ready: bool = False
    last_check: Optional[datetime] = None
    last_response_time_ms: int = 0
    consecutive_failures: int = 0
    is_cold: bool = True
    last_successful_call: Optional[datetime] = None


class AIStates(StatesGroup):
    """ÙˆØ¶Ø¹ÛŒØªâ€ŒÙ‡Ø§ÛŒ FSM"""
    chatting = State()
    waiting_for_translation = State()
    waiting_for_italian_word = State()
    selecting_help_type = State()
    waiting_for_feedback = State()
    warming_up = State()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û·: Ú©Ù„Ø§Ø³ AIServiceManager
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AIServiceManager:
    """
    Ù…Ø¯ÛŒØ±ÛŒØª Ø³Ø±ÙˆÛŒØ³ AI Ø¨Ø§ Ù‚Ø§Ø¨Ù„ÛŒØª Warm-up Ùˆ Keep-Alive
    """
    
    def __init__(self):
        self.health = ServiceHealth()
        self._lock = asyncio.Lock()
        self._warmup_in_progress = False
        self._warmup_event = asyncio.Event()
        self._keep_alive_task: Optional[asyncio.Task] = None
        
    @property
    def is_ready(self) -> bool:
        """Ø¢ÛŒØ§ Ø³Ø±ÙˆÛŒØ³ Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³ØªØŸ"""
        if not self.health.last_check:
            return False
        elapsed = (datetime.now() - self.health.last_check).total_seconds()
        return self.health.is_ready and elapsed < WARMUP_CACHE_DURATION
    
    @property
    def needs_warmup(self) -> bool:
        """Ø¢ÛŒØ§ Ù†ÛŒØ§Ø² Ø¨Ù‡ Warm-up Ø¯Ø§Ø±ÛŒÙ…ØŸ"""
        if not WARMUP_ENABLED:
            return False
        if not self.health.last_check:
            return True
        elapsed = (datetime.now() - self.health.last_check).total_seconds()
        return elapsed >= WARMUP_CACHE_DURATION
    
    @property
    def is_cold(self) -> bool:
        """Ø¢ÛŒØ§ Ø³Ø±ÙˆÛŒØ³ Ø¯Ø± Ø­Ø§Ù„Øª Cold Ø§Ø³ØªØŸ"""
        if not self.health.last_successful_call:
            return True
        elapsed = (datetime.now() - self.health.last_successful_call).total_seconds()
        return elapsed > KEEP_ALIVE_INTERVAL
    
    async def warmup(self, force: bool = False) -> bool:
        """Warm-up Ø³Ø±ÙˆÛŒØ³ AI"""
        if not force and not self.needs_warmup:
            return True
        
        if self._warmup_in_progress:
            try:
                await asyncio.wait_for(
                    self._warmup_event.wait(),
                    timeout=WARMUP_TIMEOUT_SECONDS
                )
                return self.health.is_ready
            except asyncio.TimeoutError:
                return False
        
        async with self._lock:
            self._warmup_in_progress = True
            self._warmup_event.clear()
            
            try:
                logger.info("ğŸ”¥ Starting AI service warmup...")
                start_time = datetime.now()
                
                if not AI_SERVICE_AVAILABLE or not ai_service:
                    self.health.is_ready = False
                    return False
                
                try:
                    response = await asyncio.wait_for(
                        ai_service.chat(
                            message=WARMUP_MESSAGE,
                            user_id=0,
                            use_cache=False
                        ),
                        timeout=WARMUP_TIMEOUT_SECONDS
                    )
                    
                    elapsed_ms = int((datetime.now() - start_time).total_seconds() * 1000)
                    
                    if response and response.text:
                        self.health.is_ready = True
                        self.health.last_check = datetime.now()
                        self.health.last_response_time_ms = elapsed_ms
                        self.health.consecutive_failures = 0
                        self.health.is_cold = False
                        self.health.last_successful_call = datetime.now()
                        
                        logger.success(f"âœ… AI warmup successful in {elapsed_ms}ms")
                        return True
                    else:
                        raise Exception("Empty response")
                        
                except asyncio.TimeoutError:
                    logger.warning(f"â° AI warmup timeout")
                    self.health.consecutive_failures += 1
                    self.health.is_cold = True
                    return False
                    
                except Exception as e:
                    logger.error(f"âŒ AI warmup error: {e}")
                    self.health.consecutive_failures += 1
                    return False
                    
            finally:
                self._warmup_in_progress = False
                self._warmup_event.set()
    
    async def ensure_ready(self, user_lang: str = "fa") -> Tuple[bool, str]:
        """Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² Ø¢Ù…Ø§Ø¯Ù‡ Ø¨ÙˆØ¯Ù† Ø³Ø±ÙˆÛŒØ³"""
        if self.is_ready and not self.is_cold:
            return True, "âœ…"
        
        success = await self.warmup()
        
        if success:
            return True, "âœ…"
        else:
            return False, "âš ï¸ Ø³Ø±ÙˆÛŒØ³ Ø¯Ø± Ø­Ø§Ù„ Ø¨ÛŒØ¯Ø§Ø± Ø´Ø¯Ù†..."
    
    async def health_check(self) -> Dict[str, Any]:
        """Ø¨Ø±Ø±Ø³ÛŒ Ø³Ù„Ø§Ù…Øª"""
        return {
            "is_ready": self.health.is_ready,
            "is_cold": self.is_cold,
            "last_check": self.health.last_check.isoformat() if self.health.last_check else None,
            "last_response_time_ms": self.health.last_response_time_ms,
            "consecutive_failures": self.health.consecutive_failures,
            "warmup_in_progress": self._warmup_in_progress,
            "needs_warmup": self.needs_warmup,
        }
    
    def record_success(self, response_time_ms: int) -> None:
        """Ø«Ø¨Øª ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù…ÙˆÙÙ‚"""
        self.health.is_ready = True
        self.health.last_check = datetime.now()
        self.health.last_response_time_ms = response_time_ms
        self.health.consecutive_failures = 0
        self.health.is_cold = False
        self.health.last_successful_call = datetime.now()
    
    def record_failure(self) -> None:
        """Ø«Ø¨Øª ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù†Ø§Ù…ÙˆÙÙ‚"""
        self.health.consecutive_failures += 1
        if self.health.consecutive_failures >= 3:
            self.health.is_ready = False
    
    async def start_keep_alive(self) -> None:
        """Ø´Ø±ÙˆØ¹ Keep-Alive"""
        if not KEEP_ALIVE_ENABLED:
            return
        
        if self._keep_alive_task and not self._keep_alive_task.done():
            return
        
        self._keep_alive_task = asyncio.create_task(self._keep_alive_loop())
        logger.info("ğŸ’“ Keep-alive started")
    
    async def stop_keep_alive(self) -> None:
        """ØªÙˆÙ‚Ù Keep-Alive"""
        if self._keep_alive_task:
            self._keep_alive_task.cancel()
            with suppress(asyncio.CancelledError):
                await self._keep_alive_task
            logger.info("ğŸ’“ Keep-alive stopped")
    
    async def _keep_alive_loop(self) -> None:
        """Ø­Ù„Ù‚Ù‡ Keep-Alive"""
        while True:
            try:
                await asyncio.sleep(KEEP_ALIVE_INTERVAL)
                
                if self.health.last_successful_call and AI_SERVICE_AVAILABLE and ai_service:
                    try:
                        response = await asyncio.wait_for(
                            ai_service.chat(
                                message=KEEP_ALIVE_MESSAGE,
                                user_id=0,
                                use_cache=False
                            ),
                            timeout=10
                        )
                        
                        if response:
                            self.health.last_successful_call = datetime.now()
                            self.health.is_cold = False
                            
                    except Exception as e:
                        logger.debug(f"ğŸ’“ Keep-alive ping failed: {e}")
                        
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"âŒ Keep-alive error: {e}")
                await asyncio.sleep(60)


# Ù†Ù…ÙˆÙ†Ù‡ Ø³Ø±Ø§Ø³Ø±ÛŒ
service_manager = AIServiceManager()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û¸: Ú©Ù„Ø§Ø³ Metrics
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class AIMetrics:
    """Ù…Ø¯ÛŒØ±ÛŒØª Ø¢Ù…Ø§Ø± Ùˆ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§"""
    
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0
    timeout_requests: int = 0
    cache_hits: int = 0
    cold_start_requests: int = 0
    warmup_count: int = 0
    total_response_time_ms: int = 0
    
    # Ø¢Ù…Ø§Ø± Ø¬Ø¯ÛŒØ¯
    voice_requests: int = 0
    image_requests: int = 0
    model_fallback_count: int = 0
    history_used_count: int = 0
    
    response_times: deque = field(
        default_factory=lambda: deque(maxlen=METRICS_RESPONSE_TIME_SAMPLES)
    )
    
    requests_per_user: Counter = field(default_factory=Counter)
    requests_per_model: Counter = field(default_factory=Counter)
    popular_questions: Counter = field(default_factory=Counter)
    errors_by_type: Counter = field(default_factory=Counter)
    started_at: datetime = field(default_factory=datetime.now)
    
    def record_request(
        self, 
        user_id: int, 
        question: str, 
        success: bool, 
        time_ms: int,
        from_cache: bool = False,
        error_type: Optional[str] = None,
        was_cold_start: bool = False,
        model_used: Optional[str] = None,
        was_model_fallback: bool = False,
        used_history: bool = False,
    ) -> None:
        """Ø«Ø¨Øª ÛŒÚ© Ø¯Ø±Ø®ÙˆØ§Ø³Øª"""
        self.total_requests += 1
        self.total_response_time_ms += time_ms
        
        if success:
            self.successful_requests += 1
        else:
            self.failed_requests += 1
            if error_type:
                self.errors_by_type[error_type] += 1
        
        if from_cache:
            self.cache_hits += 1
        
        if was_cold_start:
            self.cold_start_requests += 1
        
        if was_model_fallback:
            self.model_fallback_count += 1
        
        if used_history:
            self.history_used_count += 1
        
        if model_used:
            self.requests_per_model[model_used] += 1
        
        self.response_times.append(time_ms)
        self.requests_per_user[user_id] += 1
        
        short_question = question[:50].strip()
        if short_question:
            self.popular_questions[short_question] += 1
            if len(self.popular_questions) > METRICS_MAX_POPULAR_QUESTIONS:
                self.popular_questions = Counter(
                    dict(self.popular_questions.most_common(METRICS_MAX_POPULAR_QUESTIONS // 2))
                )
    
    def record_timeout(self, user_id: int) -> None:
        """Ø«Ø¨Øª timeout"""
        self.timeout_requests += 1
        self.failed_requests += 1
        self.total_requests += 1
        self.errors_by_type["timeout"] += 1
        self.requests_per_user[user_id] += 1
    
    def record_warmup(self) -> None:
        """Ø«Ø¨Øª Warm-up"""
        self.warmup_count += 1
    
    def record_voice(self) -> None:
        """Ø«Ø¨Øª Ø¯Ø±Ø®ÙˆØ§Ø³Øª ØµÙˆØªÛŒ"""
        self.voice_requests += 1
    
    def record_image(self) -> None:
        """Ø«Ø¨Øª Ø¯Ø±Ø®ÙˆØ§Ø³Øª ØªØµÙˆÛŒØ±"""
        self.image_requests += 1
    
    @property
    def success_rate(self) -> float:
        if self.total_requests == 0:
            return 0.0
        return (self.successful_requests / self.total_requests) * 100
    
    @property
    def avg_response_time_ms(self) -> float:
        if not self.response_times:
            return 0.0
        return sum(self.response_times) / len(self.response_times)
    
    @property
    def cache_hit_rate(self) -> float:
        if self.successful_requests == 0:
            return 0.0
        return (self.cache_hits / self.successful_requests) * 100
    
    @property
    def model_fallback_rate(self) -> float:
        if self.successful_requests == 0:
            return 0.0
        return (self.model_fallback_count / self.successful_requests) * 100
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "total_requests": self.total_requests,
            "successful_requests": self.successful_requests,
            "failed_requests": self.failed_requests,
            "timeout_requests": self.timeout_requests,
            "cache_hits": self.cache_hits,
            "cold_start_requests": self.cold_start_requests,
            "warmup_count": self.warmup_count,
            "voice_requests": self.voice_requests,
            "image_requests": self.image_requests,
            "model_fallback_count": self.model_fallback_count,
            "history_used_count": self.history_used_count,
            "success_rate": f"{self.success_rate:.1f}%",
            "avg_response_time_ms": f"{self.avg_response_time_ms:.0f}",
            "cache_hit_rate": f"{self.cache_hit_rate:.1f}%",
            "model_fallback_rate": f"{self.model_fallback_rate:.1f}%",
            "unique_users": len(self.requests_per_user),
            "top_models": dict(self.requests_per_model.most_common(5)),
        }
    
    def reset(self) -> Dict[str, Any]:
        """Ø±ÛŒØ³Øª Ø¢Ù…Ø§Ø±"""
        old_stats = self.to_dict()
        
        self.total_requests = 0
        self.successful_requests = 0
        self.failed_requests = 0
        self.timeout_requests = 0
        self.cache_hits = 0
        self.cold_start_requests = 0
        self.warmup_count = 0
        self.total_response_time_ms = 0
        self.voice_requests = 0
        self.image_requests = 0
        self.model_fallback_count = 0
        self.history_used_count = 0
        self.response_times = deque(maxlen=METRICS_RESPONSE_TIME_SAMPLES)
        self.requests_per_user = Counter()
        self.requests_per_model = Counter()
        self.popular_questions = Counter()
        self.errors_by_type = Counter()
        self.started_at = datetime.now()
        
        return old_stats


# Ù†Ù…ÙˆÙ†Ù‡ Ø³Ø±Ø§Ø³Ø±ÛŒ
metrics = AIMetrics()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û¹: Ù…Ø¯ÛŒØ±ÛŒØª ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú†Øª
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ChatHistoryManager:
    """
    Ù…Ø¯ÛŒØ±ÛŒØª ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú†Øª Ú©Ø§Ø±Ø¨Ø±Ø§Ù†
    
    Ø§ÛŒÙ† Ú©Ù„Ø§Ø³ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ù…Ú©Ø§Ù„Ù…Ø§Øª Ø±Ø§ Ø°Ø®ÛŒØ±Ù‡ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ù…ÛŒâ€ŒÚ©Ù†Ø¯
    ØªØ§ AI Ø¨ØªÙˆØ§Ù†Ø¯ context Ù…Ú©Ø§Ù„Ù…Ù‡ Ù‚Ø¨Ù„ÛŒ Ø±Ø§ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯.
    """
    
    def __init__(self, use_database: bool = False):
        self.use_database = use_database and DATABASE_AVAILABLE
        self._memory_history: Dict[int, List[Dict[str, Any]]] = defaultdict(list)
        self._last_activity: Dict[int, datetime] = {}
    
    async def add(
        self, 
        user_id: int, 
        role: str, 
        content: str,
        metadata: Optional[Dict[str, Any]] = None
    ) -> None:
        """Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù¾ÛŒØ§Ù… Ø¨Ù‡ ØªØ§Ø±ÛŒØ®Ú†Ù‡"""
        if not HISTORY_ENABLED:
            return
        
        entry = {
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat(),
            "metadata": metadata or {}
        }
        
        self._memory_history[user_id].append(entry)
        
        # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø³Ø§ÛŒØ²
        if len(self._memory_history[user_id]) > MAX_CHAT_HISTORY * 2:
            self._memory_history[user_id] = self._memory_history[user_id][-MAX_CHAT_HISTORY * 2:]
        
        self._last_activity[user_id] = datetime.now()
    
    async def get(
        self, 
        user_id: int, 
        limit: int = MAX_CHAT_HISTORY
    ) -> List[Dict[str, str]]:
        """Ø¯Ø±ÛŒØ§ÙØª ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú†Øª Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ AI"""
        if not HISTORY_ENABLED:
            return []
        
        history = self._memory_history.get(user_id, [])
        
        # ÙÙ‚Ø· role Ùˆ content Ø±Ø§ Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù† (ÙØ±Ù…Øª Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² AI)
        return [
            {"role": h["role"], "content": h["content"]} 
            for h in history[-limit:]
        ]
    
    async def get_full(
        self, 
        user_id: int, 
        limit: int = MAX_CHAT_HISTORY
    ) -> List[Dict[str, Any]]:
        """Ø¯Ø±ÛŒØ§ÙØª ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú©Ø§Ù…Ù„ Ø¨Ø§ Ù…ØªØ§Ø¯ÛŒØªØ§"""
        return self._memory_history.get(user_id, [])[-limit:]
    
    async def clear(self, user_id: int) -> int:
        """Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú©Ø§Ø±Ø¨Ø±"""
        count = len(self._memory_history.get(user_id, []))
        self._memory_history[user_id] = []
        self._last_activity.pop(user_id, None)
        return count
    
    async def cleanup_old_data(self) -> int:
        """Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù‚Ø¯ÛŒÙ…ÛŒ"""
        cleaned = 0
        cutoff = datetime.now() - timedelta(hours=HISTORY_MAX_AGE_HOURS)
        
        users_to_clean = [
            user_id for user_id, last_time in self._last_activity.items()
            if last_time < cutoff
        ]
        
        for user_id in users_to_clean:
            self._memory_history.pop(user_id, None)
            self._last_activity.pop(user_id, None)
            cleaned += 1
        
        if cleaned > 0:
            logger.info(f"ğŸ§¹ Cleaned history for {cleaned} users")
        
        return cleaned
    
    def get_stats(self) -> Dict[str, int]:
        """Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø±"""
        total_messages = sum(len(h) for h in self._memory_history.values())
        return {
            "total_users": len(self._memory_history),
            "total_messages": total_messages,
            "active_users": len(self._last_activity),
        }


# Ù†Ù…ÙˆÙ†Ù‡ Ø³Ø±Ø§Ø³Ø±ÛŒ
chat_history_manager = ChatHistoryManager(use_database=DATABASE_AVAILABLE)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û±Û°: Ù…Ø¯ÛŒØ±ÛŒØª Rate Limiting
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class RateLimiter:
    """Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ø­Ø¯ÙˆØ¯ÛŒØª Ù†Ø±Ø® Ø¯Ø±Ø®ÙˆØ§Ø³Øª"""
    
    def __init__(self):
        self._user_requests: Dict[int, List[datetime]] = defaultdict(list)
        self._premium_users: set = set()
    
    def add_premium_user(self, user_id: int) -> None:
        self._premium_users.add(user_id)
    
    def remove_premium_user(self, user_id: int) -> None:
        self._premium_users.discard(user_id)
    
    def is_premium(self, user_id: int) -> bool:
        return user_id in self._premium_users
    
    def check(self, user_id: int) -> Tuple[bool, int]:
        """Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­Ø¯ÙˆØ¯ÛŒØª - Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† (Ù…Ø¬Ø§Ø² Ø§Ø³Øª, Ø«Ø§Ù†ÛŒÙ‡ ØªØ§ Ù…Ø¬Ø§Ø² Ø´Ø¯Ù†)"""
        now = datetime.now()
        window_start = now - timedelta(seconds=RATE_LIMIT_WINDOW)
        
        self._user_requests[user_id] = [
            t for t in self._user_requests[user_id] if t > window_start
        ]
        
        limit = RATE_LIMIT_MESSAGES
        if self.is_premium(user_id):
            limit *= RATE_LIMIT_PREMIUM_MULTIPLIER
        
        if len(self._user_requests[user_id]) >= limit:
            oldest = min(self._user_requests[user_id])
            wait = int((oldest + timedelta(seconds=RATE_LIMIT_WINDOW) - now).total_seconds())
            return False, max(0, wait)
        
        self._user_requests[user_id].append(now)
        return True, 0
    
    def get_remaining(self, user_id: int) -> int:
        """ØªØ¹Ø¯Ø§Ø¯ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡"""
        now = datetime.now()
        window_start = now - timedelta(seconds=RATE_LIMIT_WINDOW)
        
        recent = [t for t in self._user_requests.get(user_id, []) if t > window_start]
        
        limit = RATE_LIMIT_MESSAGES
        if self.is_premium(user_id):
            limit *= RATE_LIMIT_PREMIUM_MULTIPLIER
        
        return max(0, limit - len(recent))
    
    async def cleanup(self) -> int:
        """Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ"""
        now = datetime.now()
        cutoff = now - timedelta(seconds=RATE_LIMIT_WINDOW * 2)
        cleaned = 0
        
        users_to_clean = [
            user_id for user_id, requests in self._user_requests.items()
            if all(t < cutoff for t in requests)
        ]
        
        for user_id in users_to_clean:
            del self._user_requests[user_id]
            cleaned += 1
        
        return cleaned


# Ù†Ù…ÙˆÙ†Ù‡ Ø³Ø±Ø§Ø³Ø±ÛŒ
rate_limiter = RateLimiter()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û±Û±: Ø³ÙˆØ§Ù„Ø§Øª Ù¾Ø±ØªÚ©Ø±Ø§Ø±
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

QUICK_QUESTIONS: Dict[str, Dict[str, str]] = {
    "scholarship": {
        "fa": "Ø´Ø±Ø§ÛŒØ· Ùˆ Ù…Ø±Ø§Ø­Ù„ Ø¯Ø±ÛŒØ§ÙØª Ø¨ÙˆØ±Ø³ÛŒÙ‡ DSU Ú†ÛŒØ³ØªØŸ Ú†Ù‡ Ù…Ø¯Ø§Ø±Ú©ÛŒ Ù„Ø§Ø²Ù… Ø§Ø³ØªØŸ",
        "en": "What are the requirements for DSU scholarship?",
        "it": "Quali sono i requisiti per la borsa di studio DSU?",
    },
    "permesso": {
        "fa": "Ù…Ø±Ø§Ø­Ù„ Ú¯Ø±ÙØªÙ† Ù¾Ø±Ù…Ø³Ùˆ (Ø§Ø¬Ø§Ø²Ù‡ Ø§Ù‚Ø§Ù…Øª) Ø¯Ø± Ø§ÛŒØªØ§Ù„ÛŒØ§ Ú†ÛŒØ³ØªØŸ",
        "en": "What are the steps to get a permesso in Italy?",
        "it": "Quali sono i passaggi per ottenere il permesso di soggiorno?",
    },
    "cost": {
        "fa": "Ù‡Ø²ÛŒÙ†Ù‡ Ù…Ø§Ù‡Ø§Ù†Ù‡ Ø²Ù†Ø¯Ú¯ÛŒ Ø¯Ø§Ù†Ø´Ø¬ÙˆÛŒÛŒ Ø¯Ø± Ù¾Ø±ÙˆØ¬Ø§ Ú†Ù‚Ø¯Ø± Ø§Ø³ØªØŸ",
        "en": "What is the monthly cost of living in Perugia?",
        "it": "Qual Ã¨ il costo mensile della vita a Perugia?",
    },
    "housing": {
        "fa": "Ú†Ø·ÙˆØ± Ø¯Ø± Ù¾Ø±ÙˆØ¬Ø§ Ø®Ø§Ù†Ù‡ ÛŒØ§ Ø§ØªØ§Ù‚ Ù¾ÛŒØ¯Ø§ Ú©Ù†Ù…ØŸ",
        "en": "How to find housing in Perugia?",
        "it": "Come trovare alloggio a Perugia?",
    },
    "isee": {
        "fa": "ISEE Ú†ÛŒØ³Øª Ùˆ Ú†Ø·ÙˆØ± Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŸ",
        "en": "What is ISEE and how is it calculated?",
        "it": "Cos'Ã¨ l'ISEE e come si calcola?",
    },
    "codice_fiscale": {
        "fa": "Ú©Ø¯ ÙÛŒØ³Ú©Ø§Ù„Ù‡ Ú†ÛŒØ³Øª Ùˆ Ú†Ø·ÙˆØ± Ø¯Ø±ÛŒØ§ÙØª Ú©Ù†Ù…ØŸ",
        "en": "What is Codice Fiscale and how to get it?",
        "it": "Cos'Ã¨ il Codice Fiscale e come ottenerlo?",
    },
    "university": {
        "fa": "Ø«Ø¨Øªâ€ŒÙ†Ø§Ù… Ø¯Ø± Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡ Ù¾Ø±ÙˆØ¬Ø§ Ú†Ú¯ÙˆÙ†Ù‡ Ø§Ø³ØªØŸ",
        "en": "How to enroll at the University of Perugia?",
        "it": "Come iscriversi all'UniversitÃ  di Perugia?",
    },
}


def get_quick_question(key: str, lang: str = "fa") -> str:
    """Ø¯Ø±ÛŒØ§ÙØª Ù…ØªÙ† Ø³ÙˆØ§Ù„ Ø³Ø±ÛŒØ¹"""
    return QUICK_QUESTIONS.get(key, {}).get(lang, "")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û±Û²: Ø§ÛŒÙ…ÙˆØ¬ÛŒâ€ŒÙ‡Ø§
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

SUCCESS_EMOJIS = ["âœ¨", "ğŸ¯", "ğŸ’¡", "ğŸŒŸ", "â­", "ğŸ‰", "âœ…", "ğŸ‘", "ğŸš€", "ğŸ’ª"]


def get_random_emoji() -> str:
    return random.choice(SUCCESS_EMOJIS)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û±Û³: Ø³ÛŒØ³ØªÙ… Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ú†Ù†Ø¯Ø²Ø¨Ø§Ù†Ù‡
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

MESSAGES: Dict[str, Dict[str, Any]] = {
    "fa": {
        # Ù¾Ø±Ø¯Ø§Ø²Ø´
        "thinking": [
            "ğŸ§  <i>Ø¯Ø§Ø±Ù… ÙÚ©Ø± Ù…ÛŒâ€ŒÚ©Ù†Ù…...</i>",
            "ğŸ¤” <i>ÛŒÙ‡ Ù„Ø­Ø¸Ù‡ ØµØ¨Ø± Ú©Ù†...</i>",
            "ğŸ’­ <i>Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´...</i>",
            "âš¡ <i>Ø¯Ø§Ø±Ù… Ø¬ÙˆØ§Ø¨ Ø±Ùˆ Ø¢Ù…Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ù…...</i>",
        ],
        
        # Warm-up
        "warming_up": "ğŸ”„ <i>Ø¯Ø± Ø­Ø§Ù„ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø±ÙˆÛŒØ³...</i>",
        "warming_up_done": "âœ… Ø³Ø±ÙˆÛŒØ³ Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³Øª!",
        "warming_up_failed": "âš ï¸ Ø³Ø±ÙˆÛŒØ³ Ø¯Ø± Ø­Ø§Ù„ Ø¨ÛŒØ¯Ø§Ø± Ø´Ø¯Ù† Ø§Ø³Øª...",
        "service_waking_up": "â˜• <i>Ø³Ø±ÙˆÛŒØ³ Ø¯Ø± Ø­Ø§Ù„ Ø¨ÛŒØ¯Ø§Ø± Ø´Ø¯Ù†...</i>",
        "retry_after_warmup": "ğŸ”„ Ø¯Ø± Ø­Ø§Ù„ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯...",
        
        # Voice
        "voice_processing": "ğŸ¤ <i>Ø¯Ø± Ø­Ø§Ù„ ØªØ¨Ø¯ÛŒÙ„ ØµØ¯Ø§ Ø¨Ù‡ Ù…ØªÙ†...</i>",
        "voice_too_long": "âš ï¸ Ø­Ø¯Ø§Ú©Ø«Ø± Ø·ÙˆÙ„ ÙˆÛŒØ³ {seconds} Ø«Ø§Ù†ÛŒÙ‡ Ø§Ø³Øª.",
        "voice_error": "âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØµØ¯Ø§. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.",
        "voice_empty": "âŒ Ù…ØªÙ†ÛŒ Ø§Ø² ØµØ¯Ø§ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø´Ø¯.\n\nğŸ’¡ <b>Ø±Ø§Ù‡â€ŒØ­Ù„:</b>\nâ€¢ ÙˆØ§Ø¶Ø­â€ŒØªØ± ØµØ­Ø¨Øª Ú©Ù†ÛŒØ¯\nâ€¢ Ù†ÙˆÛŒØ² Ù…Ø­ÛŒØ· Ø±Ø§ Ú©Ù… Ú©Ù†ÛŒØ¯\nâ€¢ ÛŒØ§ Ø³ÙˆØ§Ù„ØªØ§Ù† Ø±Ø§ ØªØ§ÛŒÙ¾ Ú©Ù†ÛŒØ¯",
        "voice_your_text": "ğŸ¤ <b>Ù…ØªÙ† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡:</b>",
        "voice_not_supported": "âš ï¸ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ù¾ÛŒØ§Ù… ØµÙˆØªÛŒ ÙØ¹Ø§Ù„ Ù†ÛŒØ³Øª.",
        
        # Image
        "image_processing": "ğŸ–¼ï¸ <i>Ø¯Ø± Ø­Ø§Ù„ ØªØ­Ù„ÛŒÙ„ ØªØµÙˆÛŒØ±...</i>",
        "image_too_large": "âš ï¸ Ø­Ø¯Ø§Ú©Ø«Ø± Ø­Ø¬Ù… ØªØµÙˆÛŒØ± {size}MB Ø§Ø³Øª.",
        "image_error": "âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ±.",
        "image_analysis": "ğŸ–¼ï¸ <b>ØªØ­Ù„ÛŒÙ„ ØªØµÙˆÛŒØ±:</b>",
        "image_not_supported": "âš ï¸ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² ØªØµÙˆÛŒØ± ÙØ¹Ø§Ù„ Ù†ÛŒØ³Øª.",
        "image_no_caption": "Ø§ÛŒÙ† ØªØµÙˆÛŒØ± Ø±Ø§ ØªÙˆØ¶ÛŒØ­ Ø¨Ø¯Ù‡ Ùˆ Ø§Ú¯Ø± Ù…ØªÙ†ÛŒ Ø¯Ø§Ø±Ø¯ Ø¨Ø®ÙˆØ§Ù†.",
        
        # Ù…Ø¯Ù„
        "select_model_title": "ğŸ¤– <b>Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ</b>",
        "current_model": "Ù…Ø¯Ù„ ÙØ¹Ù„ÛŒ",
        "model_selected": "âœ… Ù…Ø¯Ù„ {name} Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯!",
        "model_not_found": "âŒ Ù…Ø¯Ù„ ÛŒØ§ÙØª Ù†Ø´Ø¯",
        "model_fallback_notice": "\n\nâš ï¸ <i>ØªÙˆØ¬Ù‡: Ù…Ø¯Ù„ {original} Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†Ø¨ÙˆØ¯ØŒ Ø§Ø² {used} Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯.</i>",
        
        # Ø®ÙˆØ´Ø§Ù…Ø¯Ú¯ÙˆÛŒÛŒ
        "greeting": [
            "Ø³Ù„Ø§Ù…! ğŸ‘‹ Ú†Ø·ÙˆØ± Ù…ÛŒâ€ŒØªÙˆÙ†Ù… Ú©Ù…Ú©Øª Ú©Ù†Ù…ØŸ",
            "Ø³Ù„Ø§Ù… Ø¯ÙˆØ³Øª Ø¹Ø²ÛŒØ²! ğŸŒŸ Ø³ÙˆØ§Ù„Øª Ø±Ùˆ Ø¨Ù¾Ø±Ø³!",
            "Ù‡ÛŒ! ğŸ˜Š Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ§Ù… Ú©Ù…Ú©Øª Ú©Ù†Ù….",
        ],
        
        # Ø®Ø·Ø§
        "error": [
            "ğŸ˜… ÛŒÙ‡ Ù…Ø´Ú©Ù„ÛŒ Ù¾ÛŒØ´ Ø§ÙˆÙ…Ø¯ØŒ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø§Ù…ØªØ­Ø§Ù† Ú©Ù†!",
            "ğŸ”„ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ØŒ Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø¨ÙØ±Ø³Øª.",
        ],
        
        # Ø¹Ù…ÙˆÙ…ÛŒ
        "rate_limit": "â³ Ù„Ø·ÙØ§Ù‹ {seconds} Ø«Ø§Ù†ÛŒÙ‡ ØµØ¨Ø± Ú©Ù†ÛŒØ¯.",
        "timeout": "âš ï¸ Ù¾Ø§Ø³Ø®â€ŒØ¯Ù‡ÛŒ Ø®ÛŒÙ„ÛŒ Ø·ÙˆÙ„ Ú©Ø´ÛŒØ¯. Ù„Ø·ÙØ§Ù‹ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªÙ„Ø§Ø´ Ú©Ù†ÛŒØ¯.",
        "service_unavailable": "âš ï¸ Ø³Ø±ÙˆÛŒØ³ AI Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.",
        "empty_message": "âš ï¸ Ù„Ø·ÙØ§Ù‹ ÛŒÚ© Ù…ØªÙ† Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯!",
        "cancelled": "âŒ Ù„ØºÙˆ Ø´Ø¯.",
        "chat_ended": "âœ… Ú†Øª Ù¾Ø§ÛŒØ§Ù† ÛŒØ§ÙØª.",
        "history_cleared": "ğŸ—‘ {count} Ù¾ÛŒØ§Ù… Ù¾Ø§Ú© Ø´Ø¯!",
        "send_word": "âœï¸ ÛŒÚ© Ú©Ù„Ù…Ù‡ Ø§ÛŒØªØ§Ù„ÛŒØ§ÛŒÛŒ Ø¨ÙØ±Ø³Øª:",
        "send_text": "âœï¸ Ù…ØªÙ† Ø®ÙˆØ¯ Ø±Ø§ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯:",
        "no_access": "â›” Ø¯Ø³ØªØ±Ø³ÛŒ Ù†Ø¯Ø§Ø±ÛŒØ¯!",
        
        # Ù…Ù†Ùˆ
        "menu_title": "ğŸ¤– <b>Ø¯Ø³ØªÛŒØ§Ø± Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù¾Ø±ÙˆØ¬Ø§</b>",
        "chat_title": "ğŸ’¬ <b>Ú†Øª Ø¨Ø§ Ø¯Ø³ØªÛŒØ§Ø± Ù‡ÙˆØ´Ù…Ù†Ø¯</b>",
        "translate_title": "ğŸŒ <b>ØªØ±Ø¬Ù…Ù‡ Ù‡ÙˆØ´Ù…Ù†Ø¯</b>",
        "italian_title": "ğŸ‡®ğŸ‡¹ <b>Ú©Ù…Ú© ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø§ÛŒØªØ§Ù„ÛŒØ§ÛŒÛŒ</b>",
        "stats_title": "ğŸ“Š <b>ÙˆØ¶Ø¹ÛŒØª Ø³Ø±ÙˆÛŒØ³ AI</b>",
        "quick_title": "âš¡ <b>Ø³ÙˆØ§Ù„Ø§Øª Ù¾Ø±ØªÚ©Ø±Ø§Ø±</b>",
        
        # Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§
        "btn_start_chat": "ğŸ’¬ Ø´Ø±ÙˆØ¹ Ú†Øª",
        "btn_translate": "ğŸŒ ØªØ±Ø¬Ù…Ù‡",
        "btn_italian": "ğŸ‡®ğŸ‡¹ Ø§ÛŒØªØ§Ù„ÛŒØ§ÛŒÛŒ",
        "btn_quick": "âš¡ Ø³ÙˆØ§Ù„Ø§Øª Ø³Ø±ÛŒØ¹",
        "btn_stats": "ğŸ“Š ÙˆØ¶Ø¹ÛŒØª",
        "btn_main_menu": "ğŸ  Ù…Ù†ÙˆÛŒ Ø§ØµÙ„ÛŒ",
        "btn_ai_menu": "ğŸ”™ Ù…Ù†ÙˆÛŒ AI",
        "btn_end_chat": "âŒ Ù¾Ø§ÛŒØ§Ù†",
        "btn_clear_history": "ğŸ—‘ Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† ØªØ§Ø±ÛŒØ®Ú†Ù‡",
        "btn_refresh": "ğŸ”„ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ",
        "btn_cancel": "âŒ Ù„ØºÙˆ",
        "btn_select_model": "ğŸ¤– Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„",
        "btn_new_word": "ğŸ†• Ú©Ù„Ù…Ù‡ Ø¬Ø¯ÛŒØ¯",
        "btn_another_translate": "ğŸ”„ ØªØ±Ø¬Ù…Ù‡ Ø¯ÛŒÚ¯Ø±",
    },
    
    "en": {
        "thinking": ["ğŸ§  <i>Thinking...</i>", "ğŸ¤” <i>Just a moment...</i>"],
        "warming_up": "ğŸ”„ <i>Preparing service...</i>",
        "voice_processing": "ğŸ¤ <i>Converting speech to text...</i>",
        "voice_empty": "âŒ No text extracted. Please speak clearly or type your question.",
        "image_processing": "ğŸ–¼ï¸ <i>Analyzing image...</i>",
        "greeting": ["Hello! ğŸ‘‹ How can I help?"],
        "error": ["ğŸ˜… Something went wrong, try again!"],
        "rate_limit": "â³ Please wait {seconds} seconds.",
        "timeout": "âš ï¸ Request timed out. Please try again.",
        "model_fallback_notice": "\n\nâš ï¸ <i>Note: {original} was unavailable, used {used} instead.</i>",
    },
}


def get_msg(user_lang: str, key: str, **kwargs) -> str:
    """Ø¯Ø±ÛŒØ§ÙØª Ù¾ÛŒØ§Ù… Ø¨Ø±Ø§Ø³Ø§Ø³ Ø²Ø¨Ø§Ù†"""
    lang_messages = MESSAGES.get(user_lang, MESSAGES["fa"])
    msg = lang_messages.get(key)
    
    if msg is None:
        msg = MESSAGES["fa"].get(key, key)
    
    if isinstance(msg, list):
        msg = random.choice(msg)
    
    if kwargs:
        try:
            msg = msg.format(**kwargs)
        except (KeyError, ValueError):
            pass
    
    return msg


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û±Û´: ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ù¾Ø§ÛŒÙ‡
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def safe_answer(
    message: Message, 
    text: str, 
    reply_markup: Optional[InlineKeyboardMarkup] = None,
    parse_mode: ParseMode = ParseMode.HTML,
    **kwargs
) -> Optional[Message]:
    """Ø§Ø±Ø³Ø§Ù„ Ø§ÛŒÙ…Ù† Ù¾ÛŒØ§Ù…"""
    try:
        return await message.answer(
            text=text,
            reply_markup=reply_markup,
            parse_mode=parse_mode,
            **kwargs
        )
    except TelegramBadRequest as e:
        logger.warning(f"âš ï¸ safe_answer error: {e}")
        try:
            clean_text = text.replace("<b>", "").replace("</b>", "")
            clean_text = clean_text.replace("<i>", "").replace("</i>", "")
            return await message.answer(text=clean_text, reply_markup=reply_markup, **kwargs)
        except Exception:
            return None
    except Exception as e:
        logger.error(f"âŒ safe_answer error: {e}")
        return None


async def safe_edit_text(
    message: Message, 
    text: str, 
    reply_markup: Optional[InlineKeyboardMarkup] = None,
    parse_mode: ParseMode = ParseMode.HTML,
    disable_web_page_preview: bool = True
) -> bool:
    """ÙˆÛŒØ±Ø§ÛŒØ´ Ø§ÛŒÙ…Ù† Ù¾ÛŒØ§Ù…"""
    try:
        await message.edit_text(
            text=text,
            reply_markup=reply_markup,
            parse_mode=parse_mode,
            disable_web_page_preview=disable_web_page_preview
        )
        return True
    except TelegramBadRequest as e:
        if "message is not modified" in str(e).lower():
            return True
        logger.warning(f"âš ï¸ safe_edit_text error: {e}")
        return False
    except Exception as e:
        logger.error(f"âŒ safe_edit_text error: {e}")
        return False


async def safe_delete_message(message: Message) -> bool:
    """Ø­Ø°Ù Ø§ÛŒÙ…Ù† Ù¾ÛŒØ§Ù…"""
    try:
        await message.delete()
        return True
    except Exception:
        return False


async def safe_answer_callback(
    callback: CallbackQuery, 
    text: str = "", 
    show_alert: bool = False
) -> bool:
    """Ù¾Ø§Ø³Ø® Ø§ÛŒÙ…Ù† Ø¨Ù‡ callback"""
    try:
        await callback.answer(text=text, show_alert=show_alert)
        return True
    except Exception:
        return False


async def keep_typing(bot: Bot, chat_id: int) -> None:
    """Ø§Ø±Ø³Ø§Ù„ Ù…Ø¯Ø§ÙˆÙ… ÙˆØ¶Ø¹ÛŒØª Typing"""
    try:
        while True:
            try:
                await bot.send_chat_action(chat_id, ChatAction.TYPING)
            except Exception:
                pass
            await asyncio.sleep(TYPING_INTERVAL)
    except asyncio.CancelledError:
        pass


async def get_user_language(user_id: int, state: Optional[FSMContext] = None) -> str:
    """Ø¯Ø±ÛŒØ§ÙØª Ø²Ø¨Ø§Ù† Ú©Ø§Ø±Ø¨Ø±"""
    if state:
        try:
            data = await state.get_data()
            if "language" in data:
                return data["language"]
        except Exception:
            pass
    
    if LANG_SERVICE_AVAILABLE:
        try:
            lang_data = get_user_lang(user_id)
            return lang_data.get("code", "fa")
        except Exception:
            pass
    
    return "fa"


def is_admin(user_id: int) -> bool:
    """Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø¯Ù…ÛŒÙ† Ø¨ÙˆØ¯Ù†"""
    return settings.is_admin(user_id)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û±Ûµ: ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ú†Øª Ø¨Ø§ ØªØ§Ø±ÛŒØ®Ú†Ù‡ (Ù…Ø´Ú©Ù„ Ø§ØµÙ„ÛŒ Ø­Ù„ Ø´Ø¯!)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def chat_with_history(
    user_id: int,
    message: str,
    user_lang: str = "fa",
    model: Optional[str] = None,
    save_to_history: bool = True,
) -> Tuple[Optional[AIResponse], bool]:
    """
    ğŸ†• Ú†Øª Ø¨Ø§ AI Ù‡Ù…Ø±Ø§Ù‡ Ø¨Ø§ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ù…Ú©Ø§Ù„Ù…Ù‡
    
    Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ù…Ø´Ú©Ù„ Ø§ØµÙ„ÛŒ "ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒØ´Ù‡ ÙˆÙ„ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ù…ÛŒØ´Ù‡" Ø±Ø§ Ø­Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
    
    Ù…Ø±Ø§Ø­Ù„:
    1. Ø¯Ø±ÛŒØ§ÙØª ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ù‚Ø¨Ù„ÛŒ Ø§Ø² chat_history_manager
    2. Ø°Ø®ÛŒØ±Ù‡ Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø± Ø¯Ø± ØªØ§Ø±ÛŒØ®Ú†Ù‡
    3. Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… + ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø¨Ù‡ ai_service.chat()
    4. Ø°Ø®ÛŒØ±Ù‡ Ù¾Ø§Ø³Ø® AI Ø¯Ø± ØªØ§Ø±ÛŒØ®Ú†Ù‡
    5. Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† Ù¾Ø§Ø³Ø®
    
    Args:
        user_id: Ø´Ù†Ø§Ø³Ù‡ Ú©Ø§Ø±Ø¨Ø±
        message: Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø±
        user_lang: Ø²Ø¨Ø§Ù† Ú©Ø§Ø±Ø¨Ø±
        model: Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ (Ø§Ø®ØªÛŒØ§Ø±ÛŒØŒ Ø§Ú¯Ø± None Ø§Ø² ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ú©Ø§Ø±Ø¨Ø±)
        save_to_history: Ø¢ÛŒØ§ Ø¯Ø± ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø°Ø®ÛŒØ±Ù‡ Ø´ÙˆØ¯
        
    Returns:
        Tuple[AIResponse ÛŒØ§ None, Ø¢ÛŒØ§ Cold Start Ø¨ÙˆØ¯]
    """
    if not AI_SERVICE_AVAILABLE or not ai_service:
        return None, False
    
    was_cold_start = service_manager.is_cold
    
    # Û±. Ø¯Ø±ÛŒØ§ÙØª Ù…Ø¯Ù„
    selected_model = model or get_user_model(user_id)
    
    # Û². Ø¯Ø±ÛŒØ§ÙØª ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ù‚Ø¨Ù„ÛŒ
    history = []
    if HISTORY_ENABLED:
        history = await chat_history_manager.get(user_id, limit=MAX_CHAT_HISTORY)
        if history:
            logger.debug(f"ğŸ“œ Using {len(history)} history messages for user {user_id}")
    
    # Û³. Ø°Ø®ÛŒØ±Ù‡ Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø±
    if save_to_history and HISTORY_ENABLED:
        await chat_history_manager.add(
            user_id=user_id,
            role="user",
            content=message
        )
    
    # Û´. ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ AI Ø¨Ø§ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ùˆ Ù…Ø¯Ù„
    try:
        response = await ai_service.chat(
            message=message,
            user_id=user_id,
            context="student_assistant",
            model=selected_model,  # âœ… Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ Ú©Ø§Ø±Ø¨Ø±
            history=history,       # âœ… ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ù…Ú©Ø§Ù„Ù…Ù‡
            use_cache=CACHE_ENABLED and not history,  # Ú©Ø´ ÙÙ‚Ø· Ø¨Ø¯ÙˆÙ† ØªØ§Ø±ÛŒØ®Ú†Ù‡
        )
        
        # Ûµ. Ø°Ø®ÛŒØ±Ù‡ Ù¾Ø§Ø³Ø® AI
        if response and response.text and save_to_history and HISTORY_ENABLED:
            await chat_history_manager.add(
                user_id=user_id,
                role="assistant",
                content=response.text,
                metadata={
                    "model": response.model_key,
                    "was_fallback": response.was_model_fallback,
                }
            )
        
        # Û¶. Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ service_manager
        if response and response.is_ai_generated:
            service_manager.record_success(response.processing_time_ms)
        
        return response, was_cold_start
        
    except Exception as e:
        logger.error(f"âŒ chat_with_history error: {e}")
        service_manager.record_failure()
        return None, was_cold_start


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û±Û¶: Context Managers
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@asynccontextmanager
async def ai_processing_context(
    bot: Bot,
    chat_id: int,
    message: Message,
    user_lang: str = "fa",
    thinking_text: Optional[str] = None,
    show_keyboard: bool = False,
    keyboard: Optional[InlineKeyboardMarkup] = None,
    do_warmup: bool = True
) -> AsyncGenerator[Tuple[Message, datetime, bool], None]:
    """
    Context Manager Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´â€ŒÙ‡Ø§ÛŒ AI
    
    Usage:
        async with ai_processing_context(bot, chat_id, message) as (thinking_msg, start_time, was_cold):
            response = await chat_with_history(user_id, text)
            await safe_edit_text(thinking_msg, response.text)
    """
    was_cold = service_manager.is_cold
    
    # Warm-up
    if do_warmup and WARMUP_ENABLED and service_manager.needs_warmup:
        warmup_msg = await safe_answer(message, get_msg(user_lang, "warming_up"))
        
        warmup_success = await service_manager.warmup()
        
        if warmup_success:
            if warmup_msg:
                await safe_edit_text(warmup_msg, get_msg(user_lang, "warming_up_done"))
                await asyncio.sleep(0.5)
            metrics.record_warmup()
        else:
            if warmup_msg:
                await safe_edit_text(warmup_msg, get_msg(user_lang, "service_waking_up"))
            was_cold = True
    
    # Ù…ØªÙ† Ù¾ÛŒØ´â€ŒÙØ±Ø¶
    if thinking_text is None:
        thinking_text = get_msg(user_lang, "thinking")
        if was_cold:
            thinking_text = get_msg(user_lang, "service_waking_up") + "\n\n" + thinking_text
    
    start_time = datetime.now()
    typing_task = None
    thinking_msg = None
    
    try:
        thinking_msg = await safe_answer(
            message,
            thinking_text,
            reply_markup=keyboard if show_keyboard else None
        )
        
        if thinking_msg is None:
            thinking_msg = message
        
        typing_task = asyncio.create_task(keep_typing(bot, chat_id))
        
        yield thinking_msg, start_time, was_cold
        
    finally:
        if typing_task is not None:
            typing_task.cancel()
            with suppress(asyncio.CancelledError):
                await typing_task


@asynccontextmanager
async def callback_processing_context(
    callback: CallbackQuery,
    user_lang: str = "fa",
    thinking_text: Optional[str] = None,
    answer_text: str = "â³",
    do_warmup: bool = True
) -> AsyncGenerator[Tuple[Message, datetime, bool], None]:
    """Context Manager Ø¨Ø±Ø§ÛŒ callback Ù‡Ø§ÛŒ AI"""
    was_cold = service_manager.is_cold
    
    if do_warmup and WARMUP_ENABLED and service_manager.needs_warmup:
        await safe_answer_callback(callback, "ğŸ”„")
        await safe_edit_text(callback.message, get_msg(user_lang, "warming_up"))
        
        warmup_success = await service_manager.warmup()
        if warmup_success:
            metrics.record_warmup()
        else:
            was_cold = True
    else:
        await safe_answer_callback(callback, answer_text)
    
    if thinking_text is None:
        thinking_text = get_msg(user_lang, "thinking")
        if was_cold:
            thinking_text = get_msg(user_lang, "service_waking_up") + "\n\n" + thinking_text
    
    start_time = datetime.now()
    typing_task = None
    
    try:
        await safe_edit_text(callback.message, thinking_text)
        
        typing_task = asyncio.create_task(
            keep_typing(callback.bot, callback.message.chat.id)
        )
        
        yield callback.message, start_time, was_cold
        
    finally:
        if typing_task is not None:
            typing_task.cancel()
            with suppress(asyncio.CancelledError):
                await typing_task


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û±Û·: ØªÙˆØ§Ø¨Ø¹ ÙØ±Ù…Øªâ€ŒØ¯Ù‡ÛŒ Ù¾Ø§Ø³Ø®
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def format_ai_response(
    response: AIResponse,
    user_lang: str = "fa",
    include_metadata: bool = True,
    question: Optional[str] = None,
    was_cold_start: bool = False
) -> str:
    """
    ÙØ±Ù…Øªâ€ŒØ¯Ù‡ÛŒ Ù¾Ø§Ø³Ø® AI Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¨Ù‡ Ú©Ø§Ø±Ø¨Ø±
    
    Ø´Ø§Ù…Ù„:
    - Ù¾Ø§Ø³Ø® Ø§ØµÙ„ÛŒ
    - Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø¯Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡
    - Ù†Ù…Ø§ÛŒØ´ Fallback Ø¯Ø± ØµÙˆØ±Øª Ø§Ø³ØªÙØ§Ø¯Ù‡
    """
    emoji = get_random_emoji()
    text_parts = []
    
    # Ù†Ù…Ø§ÛŒØ´ Ø³ÙˆØ§Ù„
    if question:
        text_parts.append(f"â“ <b>Ø³ÙˆØ§Ù„:</b>\n{question}\n")
        text_parts.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n")
    
    # Ù¾Ø§Ø³Ø® Ø§ØµÙ„ÛŒ
    text_parts.append(f"{emoji} <b>Ù¾Ø§Ø³Ø®:</b>\n\n{response.text}")
    
    # Ù…ØªØ§Ø¯ÛŒØªØ§
    if include_metadata:
        text_parts.append("\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        
        # Ù…Ù†Ø¨Ø¹ Ù¾Ø§Ø³Ø®
        if response.is_ai_generated:
            source = f"ğŸ¤– AI"
            if response.model_used:
                source += f" ({response.model_used})"
        else:
            source = "ğŸ“š Ø¯Ø§Ù†Ø´ Ù…Ø­Ù„ÛŒ"
        
        if response.from_cache:
            source += " ğŸ“¦"
        
        if was_cold_start:
            source += " â„ï¸"
        
        time_info = f"â± {response.processing_time_ms}ms"
        
        text_parts.append(f"\n<i>{source} | {time_info}</i>")
        
        # Ù†Ù…Ø§ÛŒØ´ Fallback
        if response.was_model_fallback and response.original_model:
            original_info = USER_SELECTABLE_MODELS.get(response.original_model, {})
            used_info = USER_SELECTABLE_MODELS.get(response.model_key, {})
            
            original_name = original_info.get("name", response.original_model)
            used_name = used_info.get("name", response.model_key or "Unknown")
            
            text_parts.append(
                get_msg(user_lang, "model_fallback_notice", 
                       original=original_name, used=used_name)
            )
    
    return "".join(text_parts)


def format_translation_response(
    response: AIResponse,
    source_lang: str,
    target_lang: str,
    original_text: Optional[str] = None,
    user_lang: str = "fa"
) -> str:
    """ÙØ±Ù…Øªâ€ŒØ¯Ù‡ÛŒ Ù¾Ø§Ø³Ø® ØªØ±Ø¬Ù…Ù‡"""
    lang_flags = {"fa": "ğŸ‡®ğŸ‡·", "en": "ğŸ‡¬ğŸ‡§", "it": "ğŸ‡®ğŸ‡¹", "auto": "ğŸ”®"}
    
    emoji = get_random_emoji()
    src_flag = lang_flags.get(source_lang, "ğŸŒ")
    tgt_flag = lang_flags.get(target_lang, "ğŸŒ")
    
    text_parts = [f"ğŸŒ <b>ØªØ±Ø¬Ù…Ù‡ {src_flag} â†’ {tgt_flag}</b>\n\n"]
    
    if original_text:
        text_parts.append(f"ğŸ“ <b>Ù…ØªÙ† Ø§ØµÙ„ÛŒ:</b>\n{original_text}\n\n")
        text_parts.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n")
    
    text_parts.append(f"{emoji} <b>ØªØ±Ø¬Ù…Ù‡:</b>\n\n{response.text}")
    
    text_parts.append("\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    source = "ğŸ¤– AI" if response.is_ai_generated else "ğŸ“–"
    if response.model_used:
        source += f" ({response.model_used})"
    text_parts.append(f"\n<i>{source} | â± {response.processing_time_ms}ms</i>")
    
    return "".join(text_parts)


def format_italian_help_response(
    response: AIResponse,
    word: str,
    help_type: str,
    user_lang: str = "fa"
) -> str:
    """ÙØ±Ù…Øªâ€ŒØ¯Ù‡ÛŒ Ù¾Ø§Ø³Ø® Ú©Ù…Ú© Ø§ÛŒØªØ§Ù„ÛŒØ§ÛŒÛŒ"""
    help_type_names = {
        "meaning": "Ù…Ø¹Ù†ÛŒ",
        "example": "Ù…Ø«Ø§Ù„",
        "conjugate": "ØµØ±Ù ÙØ¹Ù„",
        "pronunciation": "ØªÙ„ÙØ¸"
    }
    
    emoji = get_random_emoji()
    type_name = help_type_names.get(help_type, help_type)
    
    return (
        f"ğŸ‡®ğŸ‡¹ <b>{word}</b>\n"
        f"<i>{type_name.upper()}</i>\n\n"
        f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
        f"{emoji} {response.text}\n\n"
        f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        f"<i>{'ğŸ¤– AI' if response.is_ai_generated else 'ğŸ“–'} | â± {response.processing_time_ms}ms</i>"
    )


def create_error_response(message: Optional[str] = None, user_lang: str = "fa") -> AIResponse:
    """Ø§ÛŒØ¬Ø§Ø¯ Ù¾Ø§Ø³Ø® Ø®Ø·Ø§"""
    return AIResponse(
        text=message or get_msg(user_lang, "error"),
        is_ai_generated=False,
        is_fallback=True,
        error=message
    )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ù¾Ø§ÛŒØ§Ù† Ø¨Ø®Ø´ Û± Ø§Ø² Û³
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

logger.info("ğŸ“¦ AI Handler v7.0 - Part 1/3 loaded")
logger.info(f"   â€¢ Voice Enabled: {VOICE_ENABLED}")
logger.info(f"   â€¢ Image Enabled: {IMAGE_ENABLED}")
logger.info(f"   â€¢ History Enabled: {HISTORY_ENABLED}")
logger.info(f"   â€¢ Default Model: {DEFAULT_MODEL}")
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# handlers/ai_handler.py - Ø¨Ø®Ø´ Û² Ø§Ø² Û³
# Ú©ÛŒØ¨ÙˆØ±Ø¯Ù‡Ø§ Ùˆ Ù‡Ù†Ø¯Ù„Ø±Ù‡Ø§ÛŒ Ø§ØµÙ„ÛŒ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û±Û¸: Ú©ÛŒØ¨ÙˆØ±Ø¯Ù‡Ø§
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_ai_menu_keyboard(user_lang: str = "fa") -> InlineKeyboardMarkup:
    """Ú©ÛŒØ¨ÙˆØ±Ø¯ Ù…Ù†ÙˆÛŒ Ø§ØµÙ„ÛŒ AI"""
    return InlineKeyboardMarkup(inline_keyboard=[
        [
            InlineKeyboardButton(
                text=get_msg(user_lang, "btn_start_chat"),
                callback_data="ai:start_chat"
            )
        ],
        [
            InlineKeyboardButton(
                text=get_msg(user_lang, "btn_translate"),
                callback_data="ai:translate_menu"
            ),
            InlineKeyboardButton(
                text=get_msg(user_lang, "btn_italian"),
                callback_data="ai:italian_menu"
            ),
        ],
        [
            InlineKeyboardButton(
                text=get_msg(user_lang, "btn_select_model"),
                callback_data="ai:select_model"
            )
        ],
        [
            InlineKeyboardButton(
                text=get_msg(user_lang, "btn_quick"),
                callback_data="ai:quick"
            )
        ],
        [
            InlineKeyboardButton(
                text=get_msg(user_lang, "btn_stats"),
                callback_data="ai:stats"
            )
        ],
        [
            InlineKeyboardButton(
                text=get_msg(user_lang, "btn_main_menu"),
                callback_data="main_menu"
            )
        ],
    ])


def get_chat_keyboard(user_lang: str = "fa") -> InlineKeyboardMarkup:
    """Ú©ÛŒØ¨ÙˆØ±Ø¯ Ø­ÛŒÙ† Ú†Øª"""
    return InlineKeyboardMarkup(inline_keyboard=[
        [
            InlineKeyboardButton(text="ğŸ“ Ø¨ÙˆØ±Ø³ÛŒÙ‡", callback_data="ai:q_scholarship"),
            InlineKeyboardButton(text="ğŸ›‚ Ù¾Ø±Ù…Ø³Ùˆ", callback_data="ai:q_permesso"),
        ],
        [
            InlineKeyboardButton(text="ğŸ’° Ù‡Ø²ÛŒÙ†Ù‡", callback_data="ai:q_cost"),
            InlineKeyboardButton(text="ğŸ  Ù…Ø³Ú©Ù†", callback_data="ai:q_housing"),
        ],
        [
            InlineKeyboardButton(
                text=get_msg(user_lang, "btn_clear_history"),
                callback_data="ai:clear_history"
            ),
        ],
        [
            InlineKeyboardButton(
                text=get_msg(user_lang, "btn_ai_menu"),
                callback_data="ai:menu"
            ),
            InlineKeyboardButton(
                text=get_msg(user_lang, "btn_end_chat"),
                callback_data="ai:end_chat"
            ),
        ],
    ])


def get_chat_with_model_keyboard(
    user_id: int,
    user_lang: str = "fa"
) -> InlineKeyboardMarkup:
    """Ú©ÛŒØ¨ÙˆØ±Ø¯ Ú†Øª Ø¨Ø§ Ù†Ù…Ø§ÛŒØ´ Ù…Ø¯Ù„ ÙØ¹Ù„ÛŒ"""
    current_model = get_user_model(user_id)
    model_info = USER_SELECTABLE_MODELS.get(current_model, {})
    model_icon = model_info.get("icon", "ğŸ¤–")
    model_name = model_info.get("name", current_model)
    
    # ØªØ¹Ø¯Ø§Ø¯ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®Ú†Ù‡
    history_count = len(chat_history_manager._memory_history.get(user_id, []))
    clear_text = f"ğŸ—‘ Ù¾Ø§Ú© ({history_count})" if history_count > 0 else "ğŸ—‘ Ø®Ø§Ù„ÛŒ"
    
    return InlineKeyboardMarkup(inline_keyboard=[
        [
            InlineKeyboardButton(text="ğŸ“ Ø¨ÙˆØ±Ø³ÛŒÙ‡", callback_data="ai:q_scholarship"),
            InlineKeyboardButton(text="ğŸ›‚ Ù¾Ø±Ù…Ø³Ùˆ", callback_data="ai:q_permesso"),
        ],
        [
            InlineKeyboardButton(text="ğŸ’° Ù‡Ø²ÛŒÙ†Ù‡", callback_data="ai:q_cost"),
            InlineKeyboardButton(text="ğŸ  Ù…Ø³Ú©Ù†", callback_data="ai:q_housing"),
        ],
        [
            InlineKeyboardButton(
                text=f"{model_icon} {model_name}",
                callback_data="ai:select_model"
            ),
        ],
        [
            InlineKeyboardButton(
                text=clear_text,
                callback_data="ai:clear_history"
            ),
        ],
        [
            InlineKeyboardButton(
                text=get_msg(user_lang, "btn_ai_menu"),
                callback_data="ai:menu"
            ),
            InlineKeyboardButton(
                text=get_msg(user_lang, "btn_end_chat"),
                callback_data="ai:end_chat"
            ),
        ],
    ])


def get_translate_menu_keyboard(user_lang: str = "fa") -> InlineKeyboardMarkup:
    """Ú©ÛŒØ¨ÙˆØ±Ø¯ Ù…Ù†ÙˆÛŒ ØªØ±Ø¬Ù…Ù‡"""
    return InlineKeyboardMarkup(inline_keyboard=[
        [
            InlineKeyboardButton(
                text="ğŸ‡®ğŸ‡¹ â†’ ğŸ‡®ğŸ‡·  Ø§ÛŒØªØ§Ù„ÛŒØ§ÛŒÛŒ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ",
                callback_data="ai:tr_it_fa"
            )
        ],
        [
            InlineKeyboardButton(
                text="ğŸ‡®ğŸ‡· â†’ ğŸ‡®ğŸ‡¹  ÙØ§Ø±Ø³ÛŒ Ø¨Ù‡ Ø§ÛŒØªØ§Ù„ÛŒØ§ÛŒÛŒ",
                callback_data="ai:tr_fa_it"
            )
        ],
        [
            InlineKeyboardButton(
                text="ğŸ‡¬ğŸ‡§ â†’ ğŸ‡®ğŸ‡·  Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ",
                callback_data="ai:tr_en_fa"
            )
        ],
        [
            InlineKeyboardButton(
                text="ğŸ‡®ğŸ‡· â†’ ğŸ‡¬ğŸ‡§  ÙØ§Ø±Ø³ÛŒ Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ",
                callback_data="ai:tr_fa_en"
            )
        ],
        [
            InlineKeyboardButton(
                text="ğŸ‡®ğŸ‡¹ â†’ ğŸ‡¬ğŸ‡§  Ø§ÛŒØªØ§Ù„ÛŒØ§ÛŒÛŒ Ø¨Ù‡ Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ",
                callback_data="ai:tr_it_en"
            )
        ],
        [
            InlineKeyboardButton(
                text="ğŸ”® ØªØ´Ø®ÛŒØµ Ø®ÙˆØ¯Ú©Ø§Ø± â†’ ÙØ§Ø±Ø³ÛŒ",
                callback_data="ai:tr_auto_fa"
            )
        ],
        [
            InlineKeyboardButton(
                text=get_msg(user_lang, "btn_ai_menu"),
                callback_data="ai:menu"
            )
        ],
    ])


def get_translation_result_keyboard(
    source_lang: str, 
    target_lang: str,
    user_lang: str = "fa"
) -> InlineKeyboardMarkup:
    """Ú©ÛŒØ¨ÙˆØ±Ø¯ Ù†ØªÛŒØ¬Ù‡ ØªØ±Ø¬Ù…Ù‡"""
    return InlineKeyboardMarkup(inline_keyboard=[
        [
            InlineKeyboardButton(
                text=get_msg(user_lang, "btn_another_translate"),
                callback_data=f"ai:tr_{source_lang}_{target_lang}"
            )
        ],
        [
            InlineKeyboardButton(
                text="ğŸ”„ Ù…Ù†ÙˆÛŒ ØªØ±Ø¬Ù…Ù‡",
                callback_data="ai:translate_menu"
            ),
            InlineKeyboardButton(
                text=get_msg(user_lang, "btn_ai_menu"),
                callback_data="ai:menu"
            )
        ]
    ])


def get_italian_help_keyboard(word: str, user_lang: str = "fa") -> InlineKeyboardMarkup:
    """Ú©ÛŒØ¨ÙˆØ±Ø¯ Ú©Ù…Ú© Ø§ÛŒØªØ§Ù„ÛŒØ§ÛŒÛŒ"""
    safe_word = word[:20] if word else "parola"
    
    return InlineKeyboardMarkup(inline_keyboard=[
        [
            InlineKeyboardButton(
                text="ğŸ“– Ù…Ø¹Ù†ÛŒ",
                callback_data=f"ai:it_meaning:{safe_word}"
            ),
            InlineKeyboardButton(
                text="ğŸ“ Ù…Ø«Ø§Ù„",
                callback_data=f"ai:it_example:{safe_word}"
            ),
        ],
        [
            InlineKeyboardButton(
                text="ğŸ”„ ØµØ±Ù ÙØ¹Ù„",
                callback_data=f"ai:it_conjugate:{safe_word}"
            ),
            InlineKeyboardButton(
                text="ğŸ—£ ØªÙ„ÙØ¸",
                callback_data=f"ai:it_pronounce:{safe_word}"
            ),
        ],
        [
            InlineKeyboardButton(
                text=get_msg(user_lang, "btn_new_word"),
                callback_data="ai:italian_menu"
            ),
            InlineKeyboardButton(
                text=get_msg(user_lang, "btn_ai_menu"),
                callback_data="ai:menu"
            ),
        ],
    ])


def get_back_keyboard(user_lang: str = "fa") -> InlineKeyboardMarkup:
    """Ú©ÛŒØ¨ÙˆØ±Ø¯ Ø¨Ø§Ø²Ú¯Ø´Øª"""
    return InlineKeyboardMarkup(inline_keyboard=[
        [
            InlineKeyboardButton(
                text=get_msg(user_lang, "btn_ai_menu"),
                callback_data="ai:menu"
            ),
            InlineKeyboardButton(
                text=get_msg(user_lang, "btn_main_menu"),
                callback_data="main_menu"
            ),
        ]
    ])


def get_cancel_keyboard(user_lang: str = "fa") -> InlineKeyboardMarkup:
    """Ú©ÛŒØ¨ÙˆØ±Ø¯ Ù„ØºÙˆ"""
    return InlineKeyboardMarkup(inline_keyboard=[
        [
            InlineKeyboardButton(
                text="ğŸ”„ ØªØºÛŒÛŒØ± Ø²Ø¨Ø§Ù†",
                callback_data="ai:translate_menu"
            ),
            InlineKeyboardButton(
                text=get_msg(user_lang, "btn_cancel"),
                callback_data="ai:menu"
            )
        ]
    ])


def get_quick_questions_keyboard(user_lang: str = "fa") -> InlineKeyboardMarkup:
    """Ú©ÛŒØ¨ÙˆØ±Ø¯ Ø³ÙˆØ§Ù„Ø§Øª Ø³Ø±ÛŒØ¹"""
    return InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="ğŸ“ Ø´Ø±Ø§ÛŒØ· Ø¨ÙˆØ±Ø³ÛŒÙ‡ DSU", callback_data="ai:q_scholarship")],
        [InlineKeyboardButton(text="ğŸ›‚ Ù…Ø±Ø§Ø­Ù„ Ú¯Ø±ÙØªÙ† Ù¾Ø±Ù…Ø³Ùˆ", callback_data="ai:q_permesso")],
        [InlineKeyboardButton(text="ğŸ’° Ù‡Ø²ÛŒÙ†Ù‡ Ø²Ù†Ø¯Ú¯ÛŒ Ø¯Ø± Ù¾Ø±ÙˆØ¬Ø§", callback_data="ai:q_cost")],
        [InlineKeyboardButton(text="ğŸ  Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù…Ø³Ú©Ù†", callback_data="ai:q_housing")],
        [InlineKeyboardButton(text="ğŸ§® Ù…Ø­Ø§Ø³Ø¨Ù‡ ISEE", callback_data="ai:q_isee")],
        [InlineKeyboardButton(text="ğŸ†” Ú©Ø¯ ÙÛŒØ³Ú©Ø§Ù„Ù‡", callback_data="ai:q_codice_fiscale")],
        [InlineKeyboardButton(text="ğŸ« Ø«Ø¨Øªâ€ŒÙ†Ø§Ù… Ø¯Ø§Ù†Ø´Ú¯Ø§Ù‡", callback_data="ai:q_university")],
        [InlineKeyboardButton(text="ğŸ’¬ Ø³ÙˆØ§Ù„ Ø¯ÛŒÚ¯Ù‡ Ø¯Ø§Ø±Ù…", callback_data="ai:start_chat")],
        [
            InlineKeyboardButton(
                text=get_msg(user_lang, "btn_ai_menu"),
                callback_data="ai:menu"
            )
        ],
    ])


def get_stats_keyboard(user_id: int, user_lang: str = "fa") -> InlineKeyboardMarkup:
    """Ú©ÛŒØ¨ÙˆØ±Ø¯ ØµÙØ­Ù‡ Ø¢Ù…Ø§Ø±"""
    buttons = [
        [
            InlineKeyboardButton(
                text=get_msg(user_lang, "btn_refresh"),
                callback_data="ai:stats"
            )
        ]
    ]
    
    if is_admin(user_id):
        buttons.append([
            InlineKeyboardButton(text="ğŸ—‘ Ù¾Ø§Ú© Ú©Ø´", callback_data="ai:admin_clear"),
            InlineKeyboardButton(text="ğŸ“‹ Ù…Ø¯Ù„â€ŒÙ‡Ø§", callback_data="ai:admin_models"),
        ])
        buttons.append([
            InlineKeyboardButton(text="ğŸ”§ ØªØ³Øª Ø³Ø±ÙˆÛŒØ³", callback_data="ai:admin_test"),
            InlineKeyboardButton(text="ğŸ“Š Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§", callback_data="ai:admin_metrics"),
        ])
        buttons.append([
            InlineKeyboardButton(text="ğŸ”¥ Warm-up", callback_data="ai:admin_warmup"),
            InlineKeyboardButton(text="ğŸ”„ Ø±ÛŒØ³Øª Ø¢Ù…Ø§Ø±", callback_data="ai:admin_reset_metrics"),
        ])
    
    buttons.append([
        InlineKeyboardButton(
            text=get_msg(user_lang, "btn_ai_menu"),
            callback_data="ai:menu"
        )
    ])
    
    return InlineKeyboardMarkup(inline_keyboard=buttons)


def get_model_selection_keyboard(
    current_model: str,
    user_lang: str = "fa"
) -> InlineKeyboardMarkup:
    """Ú©ÛŒØ¨ÙˆØ±Ø¯ Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„ AI"""
    buttons = []
    
    # Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ provider
    providers: Dict[str, List[Tuple[str, Dict]]] = {}
    for model_key, info in USER_SELECTABLE_MODELS.items():
        provider = info["provider"]
        if provider not in providers:
            providers[provider] = []
        providers[provider].append((model_key, info))
    
    provider_order = ["OpenAI", "Anthropic", "Google", "Meta", "xAI", "Mistral"]
    
    for provider in provider_order:
        if provider not in providers:
            continue
        
        models = providers[provider]
        
        # Ù‡Ø¯Ø± provider
        buttons.append([
            InlineKeyboardButton(
                text=f"â”â” {provider} â”â”",
                callback_data="ai:noop"
            )
        ])
        
        for model_key, info in models:
            check = "âœ… " if model_key == current_model else ""
            vision = " ğŸ–¼ï¸" if info.get("supports_vision") else ""
            audio = " ğŸ¤" if info.get("supports_audio") else ""
            
            btn_text = f"{check}{info['icon']} {info['name']}{vision}{audio}"
            
            buttons.append([
                InlineKeyboardButton(
                    text=btn_text,
                    callback_data=f"ai:set_model:{model_key}"
                )
            ])
    
    buttons.append([
        InlineKeyboardButton(
            text=get_msg(user_lang, "btn_ai_menu"),
            callback_data="ai:menu"
        )
    ])
    
    return InlineKeyboardMarkup(inline_keyboard=buttons)


def get_voice_result_keyboard(user_lang: str = "fa") -> InlineKeyboardMarkup:
    """Ú©ÛŒØ¨ÙˆØ±Ø¯ Ù†ØªÛŒØ¬Ù‡ Ù¾ÛŒØ§Ù… ØµÙˆØªÛŒ"""
    return InlineKeyboardMarkup(inline_keyboard=[
        [
            InlineKeyboardButton(text="ğŸ¤ ÙˆÛŒØ³ Ø¯ÛŒÚ¯Ù‡", callback_data="ai:start_chat"),
            InlineKeyboardButton(text="ğŸ’¬ ØªØ§ÛŒÙ¾ Ú©Ù†Ù…", callback_data="ai:start_chat"),
        ],
        [
            InlineKeyboardButton(
                text=get_msg(user_lang, "btn_ai_menu"),
                callback_data="ai:menu"
            ),
            InlineKeyboardButton(
                text=get_msg(user_lang, "btn_end_chat"),
                callback_data="ai:end_chat"
            ),
        ],
    ])


def get_image_result_keyboard(user_lang: str = "fa") -> InlineKeyboardMarkup:
    """Ú©ÛŒØ¨ÙˆØ±Ø¯ Ù†ØªÛŒØ¬Ù‡ ØªØ­Ù„ÛŒÙ„ ØªØµÙˆÛŒØ±"""
    return InlineKeyboardMarkup(inline_keyboard=[
        [
            InlineKeyboardButton(text="ğŸ–¼ï¸ ØªØµÙˆÛŒØ± Ø¯ÛŒÚ¯Ù‡", callback_data="ai:start_chat"),
            InlineKeyboardButton(text="ğŸ’¬ Ø³ÙˆØ§Ù„ Ø¨Ù¾Ø±Ø³Ù…", callback_data="ai:start_chat"),
        ],
        [
            InlineKeyboardButton(
                text=get_msg(user_lang, "btn_ai_menu"),
                callback_data="ai:menu"
            ),
            InlineKeyboardButton(
                text=get_msg(user_lang, "btn_end_chat"),
                callback_data="ai:end_chat"
            ),
        ],
    ])


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û±Û¹: Ù‡Ù†Ø¯Ù„Ø± Ù…Ù†ÙˆÛŒ Ø§ØµÙ„ÛŒ AI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.callback_query(F.data == "ai_chat")
@router.callback_query(F.data == "ai:menu")
async def show_ai_menu(callback: CallbackQuery, state: FSMContext):
    """Ù†Ù…Ø§ÛŒØ´ Ù…Ù†ÙˆÛŒ Ø§ØµÙ„ÛŒ AI"""
    user_id = callback.from_user.id
    user_lang = await get_user_language(user_id, state)
    
    logger.info(f"ğŸ“± User {user_id} opened AI menu")
    
    await state.clear()
    
    # ÙˆØ¶Ø¹ÛŒØª Ø³Ø±ÙˆÛŒØ³
    status_text = "N/A"
    status_emoji = "âšª"
    
    if AI_SERVICE_AVAILABLE and ai_service:
        try:
            status = ai_service.get_status()
            status_map = {
                "online": ("ğŸŸ¢", "Ø¢Ù†Ù„Ø§ÛŒÙ†"),
                "degraded": ("ğŸŸ¡", "Ù…Ø­Ø¯ÙˆØ¯"),
                "limited": ("ğŸŸ ", "Ú©Ù†Ø¯"),
                "offline": ("ğŸ”´", "Ø¢ÙÙ„Ø§ÛŒÙ†")
            }
            status_code = status.get("status", "unknown")
            status_emoji, status_text = status_map.get(status_code, ("âšª", status_code))
            
            if service_manager.is_cold:
                status_text += " (â„ï¸)"
            else:
                status_text += " (ğŸ”¥)"
                
        except Exception as e:
            logger.warning(f"âš ï¸ Error getting AI status: {e}")
            status_emoji = "ğŸŸ¡"
            status_text = "Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ"
    else:
        status_emoji = "ğŸ”´"
        status_text = "ØºÛŒØ±ÙØ¹Ø§Ù„"
    
    # Ù…Ø¯Ù„ ÙØ¹Ù„ÛŒ Ú©Ø§Ø±Ø¨Ø±
    current_model = get_user_model(user_id)
    model_info = USER_SELECTABLE_MODELS.get(current_model, {})
    model_display = f"{model_info.get('icon', 'ğŸ¤–')} {model_info.get('name', current_model)}"
    
    # ØªØ¹Ø¯Ø§Ø¯ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ ØªØ§Ø±ÛŒØ®Ú†Ù‡
    history_count = len(chat_history_manager._memory_history.get(user_id, []))
    
    # Ø³Ø§Ø®Øª Ù…ØªÙ†
    text = f"{get_msg(user_lang, 'menu_title')}\n\n"
    text += f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
    text += f"ğŸ”Œ <b>ÙˆØ¶Ø¹ÛŒØª:</b> {status_emoji} {status_text}\n"
    text += f"ğŸ¤– <b>Ù…Ø¯Ù„:</b> {model_display}\n"
    
    if history_count > 0:
        text += f"ğŸ’¬ <b>ØªØ§Ø±ÛŒØ®Ú†Ù‡:</b> {history_count} Ù¾ÛŒØ§Ù…\n"
    
    text += f"\n<b>âœ¨ Ø§Ù…Ú©Ø§Ù†Ø§Øª:</b>\n"
    text += f"ğŸ’¬ Ú†Øª Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø§ Ø­Ø§ÙØ¸Ù‡ Ù…Ú©Ø§Ù„Ù…Ù‡\n"
    text += f"ğŸŒ ØªØ±Ø¬Ù…Ù‡ Ø§ÛŒØªØ§Ù„ÛŒØ§ÛŒÛŒ â†” ÙØ§Ø±Ø³ÛŒ â†” Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ\n"
    text += f"ğŸ‡®ğŸ‡¹ Ú©Ù…Ú© ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ø§ÛŒØªØ§Ù„ÛŒØ§ÛŒÛŒ\n"
    
    if VOICE_ENABLED:
        text += f"ğŸ¤ Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… ØµÙˆØªÛŒ\n"
    if IMAGE_ENABLED:
        text += f"ğŸ–¼ï¸ ØªØ­Ù„ÛŒÙ„ ØªØµÙˆÛŒØ±\n"
    
    text += f"âš¡ Ø³ÙˆØ§Ù„Ø§Øª Ù¾Ø±ØªÚ©Ø±Ø§Ø±\n\n"
    text += f"ğŸ‘‡ <b>Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†:</b>"
    
    await safe_edit_text(
        callback.message,
        text,
        get_ai_menu_keyboard(user_lang)
    )
    await safe_answer_callback(callback)


@router.message(Command("ai", "ask", "chat"))
async def cmd_ai(message: Message, state: FSMContext):
    """Ø¯Ø³ØªÙˆØ± ÙˆØ±ÙˆØ¯ Ø¨Ù‡ AI"""
    user_id = message.from_user.id
    user_lang = await get_user_language(user_id, state)
    
    text = message.text or ""
    for cmd in ["/ai", "/ask", "/chat"]:
        text = text.replace(cmd, "").strip()
    
    if text:
        logger.info(f"ğŸ“ User {user_id} asked directly: {text[:50]}...")
        await state.set_state(AIStates.chatting)
        message.text = text
        await process_chat(message, state)
    else:
        await message.answer(
            f"{get_msg(user_lang, 'menu_title')}\n\nØ§Ù†ØªØ®Ø§Ø¨ Ú©Ù†:",
            reply_markup=get_ai_menu_keyboard(user_lang),
            parse_mode=ParseMode.HTML
        )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û²Û°: Ø´Ø±ÙˆØ¹ Ú†Øª
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.callback_query(F.data == "ai:start_chat")
async def start_chat(callback: CallbackQuery, state: FSMContext):
    """Ø´Ø±ÙˆØ¹ Ú†Øª ØªØ¹Ø§Ù…Ù„ÛŒ Ø¨Ø§ AI"""
    user_id = callback.from_user.id
    user_lang = await get_user_language(user_id, state)
    
    logger.info(f"ğŸ’¬ User {user_id} starting chat...")
    
    await safe_answer_callback(callback, "â³")
    
    # Warm-up
    warmup_needed = service_manager.needs_warmup or service_manager.is_cold
    
    if warmup_needed and WARMUP_ENABLED:
        warmup_text = f"{get_msg(user_lang, 'chat_title')}\n\n"
        warmup_text += f"{get_msg(user_lang, 'warming_up')}"
        
        await safe_edit_text(callback.message, warmup_text)
        
        typing_task = asyncio.create_task(
            keep_typing(callback.bot, callback.message.chat.id)
        )
        
        try:
            warmup_success = await service_manager.warmup(force=False)
            if warmup_success:
                metrics.record_warmup()
        finally:
            typing_task.cancel()
            with suppress(asyncio.CancelledError):
                await typing_task
    
    await state.set_state(AIStates.chatting)
    await state.update_data(language=user_lang)
    
    greeting = get_msg(user_lang, "greeting")
    
    # Ù…Ø¯Ù„ ÙØ¹Ù„ÛŒ
    current_model = get_user_model(user_id)
    model_info = USER_SELECTABLE_MODELS.get(current_model, {})
    model_display = f"{model_info.get('icon', 'ğŸ¤–')} {model_info.get('name', current_model)}"
    
    # ØªØ§Ø±ÛŒØ®Ú†Ù‡
    history_count = len(chat_history_manager._memory_history.get(user_id, []))
    
    # ÙˆØ¶Ø¹ÛŒØª Ø³Ø±ÙˆÛŒØ³
    if service_manager.is_cold:
        service_status = "\n\nâš ï¸ <i>Ø³Ø±ÙˆÛŒØ³ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ú©Ù…ÛŒ Ú©Ù†Ø¯ Ù¾Ø§Ø³Ø® Ø¯Ù‡Ø¯</i>"
    else:
        service_status = "\n\nâœ… <i>Ø³Ø±ÙˆÛŒØ³ Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³Øª</i>"
    
    text = f"{get_msg(user_lang, 'chat_title')}\n\n"
    text += f"{greeting}\n\n"
    text += f"ğŸ¤– <b>Ù…Ø¯Ù„:</b> {model_display}\n"
    
    if history_count > 0:
        text += f"ğŸ’¬ <b>ØªØ§Ø±ÛŒØ®Ú†Ù‡:</b> {history_count} Ù¾ÛŒØ§Ù… (Ø§Ø¯Ø§Ù…Ù‡ Ù…Ú©Ø§Ù„Ù…Ù‡ Ù‚Ø¨Ù„ÛŒ)\n"
    
    # ÙˆØ±ÙˆØ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø´Ø¯Ù‡
    input_types = ["âœï¸ Ù…ØªÙ†"]
    if VOICE_ENABLED:
        input_types.append("ğŸ¤ ÙˆÛŒØ³")
    if IMAGE_ENABLED:
        input_types.append("ğŸ–¼ï¸ ØªØµÙˆÛŒØ±")
    
    text += f"\n<b>ÙˆØ±ÙˆØ¯ÛŒâ€ŒÙ‡Ø§:</b> {' | '.join(input_types)}\n\n"
    text += f"âœï¸ <b>Ø³ÙˆØ§Ù„Øª Ø±Ùˆ Ø¨Ù†ÙˆÛŒØ³ ÛŒØ§ ÙˆÛŒØ³/Ø¹Ú©Ø³ Ø¨ÙØ±Ø³Øª...</b>"
    text += service_status
    
    await safe_edit_text(
        callback.message,
        text,
        get_chat_with_model_keyboard(user_id, user_lang)
    )


@router.callback_query(F.data == "ai:end_chat")
async def end_chat(callback: CallbackQuery, state: FSMContext):
    """Ù¾Ø§ÛŒØ§Ù† Ú†Øª"""
    user_id = callback.from_user.id
    user_lang = await get_user_language(user_id, state)
    
    logger.info(f"ğŸ‘‹ User {user_id} ended chat")
    
    await state.clear()
    
    history = await chat_history_manager.get(user_id)
    message_count = len(history) // 2
    
    text = f"âœ… <b>{get_msg(user_lang, 'chat_ended')}</b>\n\n"
    text += f"ğŸ“Š <b>Ø¢Ù…Ø§Ø± Ø§ÛŒÙ† Ø¬Ù„Ø³Ù‡:</b>\n"
    text += f"â€¢ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§: {len(history)}\n"
    text += f"â€¢ Ø³ÙˆØ§Ù„ Ùˆ Ø¬ÙˆØ§Ø¨: {message_count}\n\n"
    text += f"Ù‡Ø± ÙˆÙ‚Øª Ø®ÙˆØ§Ø³ØªÛŒ Ø¨Ø±Ú¯Ø±Ø¯! ğŸ‘‹"
    
    await safe_edit_text(
        callback.message,
        text,
        get_back_keyboard(user_lang)
    )
    await safe_answer_callback(callback, "ğŸ‘‹")


@router.callback_query(F.data == "ai:clear_history")
async def clear_chat_history_handler(callback: CallbackQuery, state: FSMContext):
    """Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú†Øª"""
    user_id = callback.from_user.id
    user_lang = await get_user_language(user_id, state)
    
    count = await chat_history_manager.clear(user_id)
    
    logger.info(f"ğŸ—‘ User {user_id} cleared {count} messages")
    
    await safe_answer_callback(
        callback,
        get_msg(user_lang, "history_cleared", count=count),
        show_alert=True
    )
    
    # Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ú©ÛŒØ¨ÙˆØ±Ø¯
    try:
        await callback.message.edit_reply_markup(
            reply_markup=get_chat_with_model_keyboard(user_id, user_lang)
        )
    except Exception:
        pass


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û²Û±: Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§ØµÙ„ÛŒ Ú†Øª (Ø¨Ø§ ØªØ§Ø±ÛŒØ®Ú†Ù‡ - Ù…Ø´Ú©Ù„ Ø§ØµÙ„ÛŒ Ø­Ù„ Ø´Ø¯!)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.message(AIStates.chatting, F.text)
async def process_chat(message: Message, state: FSMContext):
    """
    Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ù…ØªÙ†ÛŒ Ú†Øª - Ù†Ø³Ø®Ù‡ Û·.Û°
    
    âœ… ØªØºÛŒÛŒØ±Ø§Øª Ú©Ù„ÛŒØ¯ÛŒ:
    - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² chat_with_history() Ú©Ù‡ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø±Ø§ Ù‡Ù… Ø§Ø±Ø³Ø§Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
    - Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ Ú©Ø§Ø±Ø¨Ø± ÙˆØ§Ù‚Ø¹Ø§Ù‹ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
    - Ù†Ù…Ø§ÛŒØ´ Fallback Ø¯Ø± ØµÙˆØ±Øª ØªØºÛŒÛŒØ± Ù…Ø¯Ù„
    """
    user_id = message.from_user.id
    user_lang = await get_user_language(user_id, state)
    user_text = (message.text or "").strip()
    
    # Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø³ØªÙˆØ±Ø§Øª Ø®Ø±ÙˆØ¬
    cancel_commands = ["/cancel", "/stop", "Ù„ØºÙˆ", "Ø®Ø±ÙˆØ¬", "Ù¾Ø§ÛŒØ§Ù†", "cancel", "stop"]
    if user_text.lower() in cancel_commands:
        await state.clear()
        await message.answer(
            get_msg(user_lang, "cancelled"),
            reply_markup=get_back_keyboard(user_lang),
            parse_mode=ParseMode.HTML
        )
        return

    # Ø¨Ø±Ø±Ø³ÛŒ Ø®Ø§Ù„ÛŒ Ù†Ø¨ÙˆØ¯Ù†
    if not user_text:
        await message.answer(
            get_msg(user_lang, "empty_message"),
            reply_markup=get_chat_with_model_keyboard(user_id, user_lang),
            parse_mode=ParseMode.HTML
        )
        return

    # Ø¨Ø±Ø±Ø³ÛŒ Rate Limit
    allowed, wait_seconds = rate_limiter.check(user_id)
    if not allowed:
        await message.answer(
            get_msg(user_lang, "rate_limit", seconds=wait_seconds),
            parse_mode=ParseMode.HTML
        )
        return

    logger.info(f"ğŸ’¬ Chat from {user_id}: {user_text[:50]}...")
    
    # Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´
    async with ai_processing_context(
        bot=message.bot,
        chat_id=message.chat.id,
        message=message,
        user_lang=user_lang,
        do_warmup=True
    ) as (thinking_msg, start_time, was_initially_cold):
        
        try:
            # âœ… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² chat_with_history - Ù…Ø´Ú©Ù„ Ø§ØµÙ„ÛŒ Ø­Ù„ Ø´Ø¯!
            response, was_cold_start = await chat_with_history(
                user_id=user_id,
                message=user_text,
                user_lang=user_lang,
                model=None,  # Ø§Ø² ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ú©Ø§Ø±Ø¨Ø± Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
                save_to_history=True,
            )
            
            elapsed_ms = int((datetime.now() - start_time).total_seconds() * 1000)
            
            if response:
                # ØªØ¹ÛŒÛŒÙ† Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯
                history_count = len(chat_history_manager._memory_history.get(user_id, []))
                used_history = history_count > 2  # Ø­Ø¯Ø§Ù‚Ù„ ÛŒÚ© Ø±ÙØª Ùˆ Ø¨Ø±Ú¯Ø´Øª Ù‚Ø¨Ù„ÛŒ
                
                # Ø«Ø¨Øª Ù…ØªØ±ÛŒÚ©
                metrics.record_request(
                    user_id=user_id,
                    question=user_text,
                    success=True,
                    time_ms=elapsed_ms,
                    from_cache=response.from_cache,
                    was_cold_start=was_cold_start or was_initially_cold,
                    model_used=response.model_key,
                    was_model_fallback=response.was_model_fallback,
                    used_history=used_history,
                )
                
                # ÙØ±Ù…Øª Ù¾Ø§Ø³Ø®
                response.processing_time_ms = elapsed_ms
                result_text = format_ai_response(
                    response=response,
                    user_lang=user_lang,
                    include_metadata=True,
                    was_cold_start=was_cold_start
                )
                
                await safe_edit_text(
                    thinking_msg,
                    result_text,
                    get_chat_with_model_keyboard(user_id, user_lang)
                )
                
            else:
                # Timeout ÛŒØ§ Ø®Ø·Ø§
                metrics.record_timeout(user_id)
                
                if was_cold_start or was_initially_cold:
                    error_text = get_msg(user_lang, "warming_up_failed")
                    error_text += "\n\n" + get_msg(user_lang, "retry_after_warmup")
                else:
                    error_text = get_msg(user_lang, "timeout")
                
                await safe_edit_text(
                    thinking_msg,
                    error_text,
                    get_chat_with_model_keyboard(user_id, user_lang)
                )
                
        except Exception as e:
            logger.error(f"âŒ Error in process_chat: {e}")
            logger.debug(traceback.format_exc())
            
            metrics.record_request(
                user_id=user_id,
                question=user_text,
                success=False,
                time_ms=0,
                error_type=type(e).__name__
            )
            
            await safe_edit_text(
                thinking_msg,
                get_msg(user_lang, "error"),
                get_chat_with_model_keyboard(user_id, user_lang)
            )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û²Û²: Ø³ÙˆØ§Ù„Ø§Øª Ø³Ø±ÛŒØ¹
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.callback_query(F.data == "ai:quick")
async def show_quick_questions_menu(callback: CallbackQuery, state: FSMContext):
    """Ù†Ù…Ø§ÛŒØ´ Ù…Ù†ÙˆÛŒ Ø³ÙˆØ§Ù„Ø§Øª Ø³Ø±ÛŒØ¹"""
    user_id = callback.from_user.id
    user_lang = await get_user_language(user_id, state)
    
    await state.clear()
    
    text = f"{get_msg(user_lang, 'quick_title')}\n\n"
    text += "ÛŒÚ©ÛŒ Ø±Ùˆ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù† ØªØ§ Ø³Ø±ÛŒØ¹ Ø¬ÙˆØ§Ø¨ Ø¨Ú¯ÛŒØ±ÛŒ:\n\n"
    text += "ğŸ’¡ <i>Ø§ÛŒÙ† Ø³ÙˆØ§Ù„Ø§Øª Ø§Ø² Ù¾ÛŒØ´ Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯</i>"
    
    await safe_edit_text(
        callback.message,
        text,
        get_quick_questions_keyboard(user_lang)
    )
    await safe_answer_callback(callback)


@router.callback_query(F.data.startswith("ai:q_"))
async def handle_quick_question(callback: CallbackQuery, state: FSMContext):
    """Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø³ÙˆØ§Ù„Ø§Øª Ø³Ø±ÛŒØ¹"""
    user_id = callback.from_user.id
    user_lang = await get_user_language(user_id, state)
    
    q_key = callback.data.replace("ai:q_", "")
    question = get_quick_question(q_key, user_lang)
    
    if not question:
        question = "Ø³ÙˆØ§Ù„ Ù†Ø§Ù…Ø´Ø®Øµ"
    
    logger.info(f"âš¡ Quick question from {user_id}: {q_key}")
    
    await state.set_state(AIStates.chatting)
    
    async with callback_processing_context(
        callback=callback,
        user_lang=user_lang,
        thinking_text=f"â“ <b>Ø³ÙˆØ§Ù„:</b>\n{question}\n\n{get_msg(user_lang, 'thinking')}",
        do_warmup=True
    ) as (msg, start_time, was_initially_cold):
        
        try:
            # âœ… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² chat_with_history
            response, was_cold_start = await chat_with_history(
                user_id=user_id,
                message=question,
                user_lang=user_lang,
                save_to_history=True,
            )
            
            elapsed_ms = int((datetime.now() - start_time).total_seconds() * 1000)
            
            if response:
                metrics.record_request(
                    user_id=user_id,
                    question=f"[QUICK:{q_key}] {question[:30]}",
                    success=True,
                    time_ms=elapsed_ms,
                    from_cache=response.from_cache,
                    was_cold_start=was_cold_start or was_initially_cold,
                    model_used=response.model_key,
                    was_model_fallback=response.was_model_fallback,
                )
                
                response.processing_time_ms = elapsed_ms
                result_text = format_ai_response(
                    response=response,
                    user_lang=user_lang,
                    include_metadata=True,
                    question=question,
                    was_cold_start=was_cold_start
                )
                
                await safe_edit_text(
                    msg, 
                    result_text, 
                    get_chat_with_model_keyboard(user_id, user_lang)
                )
            else:
                metrics.record_timeout(user_id)
                await safe_edit_text(
                    msg,
                    f"â“ <b>Ø³ÙˆØ§Ù„:</b>\n{question}\n\n{get_msg(user_lang, 'timeout')}",
                    get_chat_with_model_keyboard(user_id, user_lang)
                )
                
        except Exception as e:
            logger.error(f"âŒ Error in quick question: {e}")
            await safe_edit_text(
                msg,
                get_msg(user_lang, "error"),
                get_chat_with_model_keyboard(user_id, user_lang)
            )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û²Û³: Ù‡Ù†Ø¯Ù„Ø± Voice (Ù¾ÛŒØ§Ù… ØµÙˆØªÛŒ) - Ø¨Ø§ OpenRouter
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.message(AIStates.chatting, F.voice)
async def handle_voice_message(message: Message, state: FSMContext):
    """
    Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾ÛŒØ§Ù… ØµÙˆØªÛŒ - Ù†Ø³Ø®Ù‡ Û·.Û°
    
    âœ… Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ai_service.transcribe_audio() Ø¨Ø§ OpenRouter
    âœ… Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ OPENAI_API_KEY Ù†ÛŒØ³Øª!
    """
    user_id = message.from_user.id
    user_lang = await get_user_language(user_id, state)
    
    # Ø¨Ø±Ø±Ø³ÛŒ ÙØ¹Ø§Ù„ Ø¨ÙˆØ¯Ù†
    if not VOICE_ENABLED:
        await message.answer(
            get_msg(user_lang, "voice_not_supported"),
            parse_mode=ParseMode.HTML
        )
        return
    
    # Ø¨Ø±Ø±Ø³ÛŒ Ø·ÙˆÙ„ ÙˆÛŒØ³
    voice_duration = message.voice.duration
    if voice_duration > VOICE_MAX_DURATION_SECONDS:
        await message.answer(
            get_msg(user_lang, "voice_too_long", seconds=VOICE_MAX_DURATION_SECONDS),
            parse_mode=ParseMode.HTML
        )
        return
    
    # Rate Limit
    allowed, wait_seconds = rate_limiter.check(user_id)
    if not allowed:
        await message.answer(
            get_msg(user_lang, "rate_limit", seconds=wait_seconds),
            parse_mode=ParseMode.HTML
        )
        return
    
    logger.info(f"ğŸ¤ Voice message from {user_id}, duration: {voice_duration}s")
    metrics.record_voice()
    
    async with ai_processing_context(
        bot=message.bot,
        chat_id=message.chat.id,
        message=message,
        user_lang=user_lang,
        thinking_text=get_msg(user_lang, "voice_processing"),
        do_warmup=True
    ) as (thinking_msg, start_time, was_initially_cold):
        
        try:
            # Û±. Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ
            file = await message.bot.get_file(message.voice.file_id)
            file_bytes = await message.bot.download_file(file.file_path)
            
            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ bytes
            if hasattr(file_bytes, 'read'):
                audio_data = file_bytes.read()
            elif isinstance(file_bytes, io.BytesIO):
                audio_data = file_bytes.getvalue()
            else:
                audio_data = file_bytes
            
            # Û². ØªØ¨Ø¯ÛŒÙ„ ØµØ¯Ø§ Ø¨Ù‡ Ù…ØªÙ† Ø¨Ø§ OpenRouter
            if AI_SERVICE_AVAILABLE and ai_service:
                transcribed_text, error = await ai_service.transcribe_audio(
                    audio_data=audio_data,
                    language=user_lang,
                    audio_format="ogg"
                )
            else:
                transcribed_text = None
                error = "Ø³Ø±ÙˆÛŒØ³ AI Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª"
            
            if error or not transcribed_text:
                await safe_edit_text(
                    thinking_msg,
                    get_msg(user_lang, "voice_empty"),
                    get_chat_with_model_keyboard(user_id, user_lang)
                )
                return
            
            # Û³. Ù†Ù…Ø§ÛŒØ´ Ù…ØªÙ† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡
            await safe_edit_text(
                thinking_msg,
                f"{get_msg(user_lang, 'voice_your_text')}\n{transcribed_text}\n\n{get_msg(user_lang, 'thinking')}"
            )
            
            # Û´. Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ AI Ø¨Ø§ ØªØ§Ø±ÛŒØ®Ú†Ù‡
            response, was_cold_start = await chat_with_history(
                user_id=user_id,
                message=transcribed_text,
                user_lang=user_lang,
                save_to_history=True,
            )
            
            elapsed_ms = int((datetime.now() - start_time).total_seconds() * 1000)
            
            if response:
                metrics.record_request(
                    user_id=user_id,
                    question=f"[VOICE] {transcribed_text[:30]}",
                    success=True,
                    time_ms=elapsed_ms,
                    from_cache=response.from_cache,
                    was_cold_start=was_cold_start or was_initially_cold,
                    model_used=response.model_key,
                )
                
                response.processing_time_ms = elapsed_ms
                
                result_text = f"ğŸ¤ <b>Ø³ÙˆØ§Ù„ Ø´Ù…Ø§:</b>\n{transcribed_text}\n\n"
                result_text += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
                result_text += format_ai_response(
                    response=response,
                    user_lang=user_lang,
                    include_metadata=True,
                    was_cold_start=was_cold_start
                )
                
                await safe_edit_text(
                    thinking_msg,
                    result_text,
                    get_voice_result_keyboard(user_lang)
                )
            else:
                metrics.record_timeout(user_id)
                await safe_edit_text(
                    thinking_msg,
                    f"ğŸ¤ <b>Ù…ØªÙ†:</b>\n{transcribed_text}\n\n{get_msg(user_lang, 'timeout')}",
                    get_chat_with_model_keyboard(user_id, user_lang)
                )
                
        except Exception as e:
            logger.error(f"âŒ Voice processing error: {e}")
            logger.debug(traceback.format_exc())
            await safe_edit_text(
                thinking_msg,
                get_msg(user_lang, "voice_error"),
                get_chat_with_model_keyboard(user_id, user_lang)
            )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û²Û´: Ù‡Ù†Ø¯Ù„Ø± Image (ØªØµÙˆÛŒØ±)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.message(AIStates.chatting, F.photo)
async def handle_image_message(message: Message, state: FSMContext):
    """Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ±"""
    user_id = message.from_user.id
    user_lang = await get_user_language(user_id, state)
    
    if not IMAGE_ENABLED:
        await message.answer(
            get_msg(user_lang, "image_not_supported"),
            parse_mode=ParseMode.HTML
        )
        return
    
    # Rate Limit
    allowed, wait_seconds = rate_limiter.check(user_id)
    if not allowed:
        await message.answer(
            get_msg(user_lang, "rate_limit", seconds=wait_seconds),
            parse_mode=ParseMode.HTML
        )
        return
    
    # Ø¨Ø²Ø±Ú¯ØªØ±ÛŒÙ† Ø³Ø§ÛŒØ²
    photo = message.photo[-1]
    
    # Caption ÛŒØ§ Ù¾ÛŒØ´â€ŒÙØ±Ø¶
    user_prompt = message.caption or get_msg(user_lang, "image_no_caption")
    
    logger.info(f"ğŸ–¼ï¸ Image from {user_id}, prompt: {user_prompt[:30]}...")
    metrics.record_image()
    
    async with ai_processing_context(
        bot=message.bot,
        chat_id=message.chat.id,
        message=message,
        user_lang=user_lang,
        thinking_text=get_msg(user_lang, "image_processing"),
        do_warmup=True
    ) as (thinking_msg, start_time, was_initially_cold):
        
        try:
            # Ø¯Ø§Ù†Ù„ÙˆØ¯ ØªØµÙˆÛŒØ±
            file = await message.bot.get_file(photo.file_id)
            file_bytes = await message.bot.download_file(file.file_path)
            
            if hasattr(file_bytes, 'read'):
                image_data = file_bytes.read()
            elif isinstance(file_bytes, io.BytesIO):
                image_data = file_bytes.getvalue()
            else:
                image_data = file_bytes
            
            # ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Vision API
            if AI_SERVICE_AVAILABLE and ai_service:
                response = await ai_service.analyze_image(
                    image_data=image_data,
                    prompt=user_prompt,
                    user_id=user_id
                )
            else:
                response = create_error_response("Ø³Ø±ÙˆÛŒØ³ AI Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª", user_lang)
            
            elapsed_ms = int((datetime.now() - start_time).total_seconds() * 1000)
            
            if response and response.is_ai_generated:
                # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ØªØ§Ø±ÛŒØ®Ú†Ù‡
                await chat_history_manager.add(
                    user_id, "user",
                    f"[ğŸ–¼ï¸ Image] {user_prompt}"
                )
                await chat_history_manager.add(
                    user_id, "assistant",
                    response.text
                )
                
                metrics.record_request(
                    user_id=user_id,
                    question=f"[IMAGE] {user_prompt[:30]}",
                    success=True,
                    time_ms=elapsed_ms,
                    model_used=response.model_key,
                )
                
                result_text = f"{get_msg(user_lang, 'image_analysis')}\n\n"
                result_text += response.text
                result_text += "\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
                result_text += f"\n<i>ğŸ¤– {response.model_used} | â± {elapsed_ms}ms</i>"
                
                await safe_edit_text(
                    thinking_msg,
                    result_text,
                    get_image_result_keyboard(user_lang)
                )
            else:
                error_msg = response.error if response else "Ø®Ø·Ø§ÛŒ Ù†Ø§Ø´Ù†Ø§Ø®ØªÙ‡"
                await safe_edit_text(
                    thinking_msg,
                    f"{get_msg(user_lang, 'image_error')}\n\n<i>{error_msg}</i>",
                    get_chat_with_model_keyboard(user_id, user_lang)
                )
                
        except Exception as e:
            logger.error(f"âŒ Image handling error: {e}")
            await safe_edit_text(
                thinking_msg,
                get_msg(user_lang, "image_error"),
                get_chat_with_model_keyboard(user_id, user_lang)
            )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û²Ûµ: Ù‡Ù†Ø¯Ù„Ø±Ù‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.callback_query(F.data == "ai:select_model")
async def show_model_selection(callback: CallbackQuery, state: FSMContext):
    """Ù†Ù…Ø§ÛŒØ´ Ù…Ù†ÙˆÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„"""
    user_id = callback.from_user.id
    user_lang = await get_user_language(user_id, state)
    
    current_model = get_user_model(user_id)
    current_info = USER_SELECTABLE_MODELS.get(current_model, {})
    
    text = f"{get_msg(user_lang, 'select_model_title')}\n\n"
    
    if current_info:
        text += f"<b>{get_msg(user_lang, 'current_model')}:</b> "
        text += f"{current_info.get('icon', '')} {current_info.get('name', current_model)}\n"
        text += f"<i>{current_info.get('description', '')}</i>\n\n"
    
    text += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
    text += "ğŸ–¼ï¸ = Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² ØªØµÙˆÛŒØ±\n"
    text += "ğŸ¤ = Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² ØµØ¯Ø§\n"
    text += "âœ… = Ù…Ø¯Ù„ ÙØ¹Ù„ÛŒ Ø´Ù…Ø§\n\n"
    text += "Ù…Ø¯Ù„ Ù…ÙˆØ±Ø¯ Ù†Ø¸Ø±Øª Ø±Ùˆ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†:"
    
    await safe_edit_text(
        callback.message,
        text,
        get_model_selection_keyboard(current_model, user_lang)
    )
    await safe_answer_callback(callback)


@router.callback_query(F.data.startswith("ai:set_model:"))
async def handle_model_selection(callback: CallbackQuery, state: FSMContext):
    """Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ"""
    user_id = callback.from_user.id
    user_lang = await get_user_language(user_id, state)
    
    model_key = callback.data.replace("ai:set_model:", "")
    
    if set_user_model(user_id, model_key):
        model_info = USER_SELECTABLE_MODELS.get(model_key, {})
        model_name = model_info.get("name", model_key)
        
        await safe_answer_callback(
            callback,
            get_msg(user_lang, "model_selected", name=model_name),
            show_alert=True
        )
        
        # Ø¢Ù¾Ø¯ÛŒØª ØµÙØ­Ù‡
        await show_model_selection(callback, state)
    else:
        await safe_answer_callback(
            callback,
            get_msg(user_lang, "model_not_found"),
            show_alert=True
        )


@router.callback_query(F.data == "ai:noop")
async def noop_callback(callback: CallbackQuery):
    """Ø¹Ø¯Ù… Ø§Ù†Ø¬Ø§Ù… Ú©Ø§Ø± (Ø¨Ø±Ø§ÛŒ Ù‡Ø¯Ø±Ù‡Ø§)"""
    await safe_answer_callback(callback)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ù¾Ø§ÛŒØ§Ù† Ø¨Ø®Ø´ Û² Ø§Ø² Û³
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

logger.info("ğŸ“¦ AI Handler v7.0 - Part 2/3 loaded (Keyboards, Menu, Chat, Voice, Image, Model)")
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# handlers/ai_handler.py - Ø¨Ø®Ø´ Û³ Ø§Ø² Û³
# ØªØ±Ø¬Ù…Ù‡ØŒ Ø§ÛŒØªØ§Ù„ÛŒØ§ÛŒÛŒØŒ Ø¢Ù…Ø§Ø±ØŒ Ø§Ø¯Ù…ÛŒÙ†ØŒ Ùˆ ØªÙˆØ§Ø¨Ø¹ Ù†Ù‡Ø§ÛŒÛŒ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û²Û¶: Ù…ØªØ±Ø¬Ù… Ù‡ÙˆØ´Ù…Ù†Ø¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.callback_query(F.data == "translate")
@router.callback_query(F.data == "ai_translate")
@router.callback_query(F.data == "ai:translate_menu")
async def show_translate_menu(callback: CallbackQuery, state: FSMContext):
    """Ù†Ù…Ø§ÛŒØ´ Ù…Ù†ÙˆÛŒ ØªØ±Ø¬Ù…Ù‡"""
    user_id = callback.from_user.id
    user_lang = await get_user_language(user_id, state)
    
    await state.clear()
    
    text = f"{get_msg(user_lang, 'translate_title')}\n\n"
    text += "Ø²Ø¨Ø§Ù† Ù…Ø¨Ø¯Ø£ Ùˆ Ù…Ù‚ØµØ¯ Ø±Ùˆ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†:\n\n"
    text += "ğŸ’¡ <i>ÛŒØ§ Â«ØªØ´Ø®ÛŒØµ Ø®ÙˆØ¯Ú©Ø§Ø±Â» Ø±Ùˆ Ø¨Ø²Ù†!</i>"
    
    await safe_edit_text(
        callback.message,
        text,
        get_translate_menu_keyboard(user_lang)
    )
    await safe_answer_callback(callback)


@router.callback_query(F.data.startswith("ai:tr_"))
async def select_translation(callback: CallbackQuery, state: FSMContext):
    """Ø§Ù†ØªØ®Ø§Ø¨ Ø²Ø¨Ø§Ù† ØªØ±Ø¬Ù…Ù‡"""
    user_id = callback.from_user.id
    user_lang = await get_user_language(user_id, state)
    
    data = callback.data.replace("ai:tr_", "")
    
    if "_" in data:
        parts = data.split("_")
        source_lang = parts[0]
        target_lang = parts[1] if len(parts) > 1 else "fa"
    else:
        source_lang = "auto"
        target_lang = "fa"
    
    await state.update_data(
        tr_source=source_lang,
        tr_target=target_lang,
        language=user_lang
    )
    await state.set_state(AIStates.waiting_for_translation)
    
    lang_names = {
        "it": "Ø§ÛŒØªØ§Ù„ÛŒØ§ÛŒÛŒ ğŸ‡®ğŸ‡¹",
        "en": "Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ ğŸ‡¬ğŸ‡§",
        "fa": "ÙØ§Ø±Ø³ÛŒ ğŸ‡®ğŸ‡·",
        "auto": "ØªØ´Ø®ÛŒØµ Ø®ÙˆØ¯Ú©Ø§Ø± ğŸ”®"
    }
    
    source_name = lang_names.get(source_lang, source_lang)
    target_name = lang_names.get(target_lang, target_lang)
    
    text = f"ğŸŒ <b>ØªØ±Ø¬Ù…Ù‡ {source_name} â†’ {target_name}</b>\n\n"
    text += f"{get_msg(user_lang, 'send_text')}\n\n"
    text += "âŒ Ù„ØºÙˆ: /cancel"
    
    await safe_edit_text(
        callback.message,
        text,
        get_cancel_keyboard(user_lang)
    )
    await safe_answer_callback(callback)


@router.message(AIStates.waiting_for_translation)
async def process_translation(message: Message, state: FSMContext):
    """Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØ±Ø¬Ù…Ù‡"""
    user_id = message.from_user.id
    data = await state.get_data()
    user_lang = data.get("language", "fa")
    source_lang = data.get("tr_source", "auto")
    target_lang = data.get("tr_target", "fa")
    
    text_to_translate = (message.text or "").strip()
    
    # Ù„ØºÙˆ
    if text_to_translate.lower() in ["/cancel", "Ù„ØºÙˆ", "cancel"]:
        await state.clear()
        await message.answer(
            get_msg(user_lang, "cancelled"),
            reply_markup=get_back_keyboard(user_lang),
            parse_mode=ParseMode.HTML
        )
        return
    
    if not text_to_translate:
        await message.answer(
            get_msg(user_lang, "empty_message"),
            parse_mode=ParseMode.HTML
        )
        return
    
    # Rate Limit
    allowed, wait_seconds = rate_limiter.check(user_id)
    if not allowed:
        await message.answer(
            get_msg(user_lang, "rate_limit", seconds=wait_seconds),
            parse_mode=ParseMode.HTML
        )
        return
    
    logger.info(f"ğŸŒ Translation from {user_id}: {source_lang} â†’ {target_lang}")
    
    async with ai_processing_context(
        bot=message.bot,
        chat_id=message.chat.id,
        message=message,
        user_lang=user_lang,
        do_warmup=True
    ) as (thinking_msg, start_time, was_initially_cold):
        
        try:
            if AI_SERVICE_AVAILABLE and ai_service:
                actual_source = source_lang if source_lang != "auto" else "it"
                
                # Ø¯Ø±ÛŒØ§ÙØª Ù…Ø¯Ù„ Ú©Ø§Ø±Ø¨Ø±
                user_model = get_user_model(user_id)
                
                response = await ai_service.translate(
                    text=text_to_translate,
                    source_lang=actual_source,
                    target_lang=target_lang,
                    model=user_model,
                    use_cache=CACHE_ENABLED,
                )
                
                elapsed_ms = int((datetime.now() - start_time).total_seconds() * 1000)
                
                if response and response.text:
                    metrics.record_request(
                        user_id=user_id,
                        question=f"[TR:{source_lang}â†’{target_lang}]",
                        success=True,
                        time_ms=elapsed_ms,
                        from_cache=response.from_cache,
                        was_cold_start=was_initially_cold,
                        model_used=response.model_key,
                        was_model_fallback=response.was_model_fallback,
                    )
                    
                    await safe_edit_text(
                        thinking_msg,
                        response.text,
                        get_translation_result_keyboard(source_lang, target_lang, user_lang)
                    )
                else:
                    await safe_edit_text(
                        thinking_msg,
                        get_msg(user_lang, "timeout"),
                        get_translate_menu_keyboard(user_lang)
                    )
            else:
                await safe_edit_text(
                    thinking_msg,
                    get_msg(user_lang, "service_unavailable"),
                    get_back_keyboard(user_lang)
                )
                
        except Exception as e:
            logger.error(f"âŒ Translation error: {e}")
            await safe_edit_text(
                thinking_msg,
                get_msg(user_lang, "error"),
                get_translate_menu_keyboard(user_lang)
            )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û²Û·: Ø¯Ø³ØªÛŒØ§Ø± Ø²Ø¨Ø§Ù† Ø§ÛŒØªØ§Ù„ÛŒØ§ÛŒÛŒ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.callback_query(F.data == "italian")
@router.callback_query(F.data == "ai_italian_help")
@router.callback_query(F.data == "ai:italian_menu")
async def show_italian_menu(callback: CallbackQuery, state: FSMContext):
    """Ù…Ù†ÙˆÛŒ Ú©Ù…Ú© Ø§ÛŒØªØ§Ù„ÛŒØ§ÛŒÛŒ"""
    user_id = callback.from_user.id
    user_lang = await get_user_language(user_id, state)
    
    await state.clear()
    await state.set_state(AIStates.waiting_for_italian_word)
    await state.update_data(language=user_lang)
    
    text = f"{get_msg(user_lang, 'italian_title')}\n\n"
    text += f"{get_msg(user_lang, 'send_word')}\n\n"
    text += "ğŸ“– Ù…Ø¹Ù†ÛŒ Ùˆ ØªÙˆØ¶ÛŒØ­\n"
    text += "ğŸ“ Ù…Ø«Ø§Ù„ Ú©Ø§Ø±Ø¨Ø±Ø¯ÛŒ\n"
    text += "ğŸ”„ ØµØ±Ù ÙØ¹Ù„\n"
    text += "ğŸ—£ ØªÙ„ÙØ¸ ØµØ­ÛŒØ­\n\n"
    text += "âŒ Ù„ØºÙˆ: /cancel"
    
    await safe_edit_text(
        callback.message,
        text,
        get_back_keyboard(user_lang)
    )
    await safe_answer_callback(callback)


@router.message(AIStates.waiting_for_italian_word)
async def receive_italian_word(message: Message, state: FSMContext):
    """Ø¯Ø±ÛŒØ§ÙØª Ú©Ù„Ù…Ù‡ Ø§ÛŒØªØ§Ù„ÛŒØ§ÛŒÛŒ"""
    user_id = message.from_user.id
    data = await state.get_data()
    user_lang = data.get("language", "fa")
    
    word = (message.text or "").strip()
    
    if word.lower() in ["/cancel", "Ù„ØºÙˆ", "cancel"]:
        await state.clear()
        await message.answer(
            get_msg(user_lang, "cancelled"),
            reply_markup=get_back_keyboard(user_lang),
            parse_mode=ParseMode.HTML
        )
        return
    
    if not word:
        await message.answer(
            get_msg(user_lang, "empty_message"),
            parse_mode=ParseMode.HTML
        )
        return
    
    await state.update_data(italian_word=word)
    
    text = f"ğŸ‡®ğŸ‡¹ <b>{word}</b>\n\n"
    text += "Ú†Ù‡ Ú©Ù…Ú©ÛŒ Ù…ÛŒâ€ŒØ®ÙˆØ§ÛŒØŸ ğŸ‘‡"
    
    await message.answer(
        text,
        reply_markup=get_italian_help_keyboard(word, user_lang),
        parse_mode=ParseMode.HTML
    )


@router.callback_query(F.data.startswith("ai:it_"))
async def process_italian_help(callback: CallbackQuery, state: FSMContext):
    """Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ Ú©Ù…Ú© Ø§ÛŒØªØ§Ù„ÛŒØ§ÛŒÛŒ"""
    user_id = callback.from_user.id
    data = await state.get_data()
    user_lang = data.get("language", "fa")
    
    callback_data = callback.data.replace("ai:it_", "")
    parts = callback_data.split(":", 1)
    
    help_type = parts[0]
    word = parts[1] if len(parts) > 1 else ""
    
    if not word or word == "parola":
        word = data.get("italian_word", "")
    
    if not word:
        await safe_answer_callback(
            callback,
            "âŒ Ú©Ù„Ù…Ù‡ Ù…Ø´Ø®Øµ Ù†ÛŒØ³Øª",
            show_alert=True
        )
        return
    
    help_type_map = {
        "meaning": "meaning",
        "example": "example",
        "conjugate": "conjugate",
        "pronounce": "pronunciation"
    }
    
    actual_help_type = help_type_map.get(help_type, "meaning")
    
    logger.info(f"ğŸ‡®ğŸ‡¹ Italian help from {user_id}: {help_type} for '{word}'")
    
    async with callback_processing_context(
        callback=callback,
        user_lang=user_lang,
        thinking_text=f"ğŸ‡®ğŸ‡¹ <b>{word}</b>\n\n{get_msg(user_lang, 'thinking')}",
        do_warmup=True
    ) as (msg, start_time, was_initially_cold):
        
        try:
            if AI_SERVICE_AVAILABLE and ai_service:
                user_model = get_user_model(user_id)
                
                response = await ai_service.italian_helper(
                    word=word,
                    help_type=actual_help_type,
                    model=user_model,
                )
                
                elapsed_ms = int((datetime.now() - start_time).total_seconds() * 1000)
                
                if response and response.text:
                    metrics.record_request(
                        user_id=user_id,
                        question=f"[IT:{help_type}] {word}",
                        success=True,
                        time_ms=elapsed_ms,
                        from_cache=response.from_cache,
                        was_cold_start=was_initially_cold,
                        model_used=response.model_key,
                    )
                    
                    response.processing_time_ms = elapsed_ms
                    result_text = format_italian_help_response(
                        response=response,
                        word=word,
                        help_type=actual_help_type,
                        user_lang=user_lang
                    )
                    
                    await safe_edit_text(
                        msg,
                        result_text,
                        get_italian_help_keyboard(word, user_lang)
                    )
                else:
                    await safe_edit_text(
                        msg,
                        get_msg(user_lang, "timeout"),
                        get_italian_help_keyboard(word, user_lang)
                    )
            else:
                await safe_edit_text(
                    msg,
                    get_msg(user_lang, "service_unavailable"),
                    get_back_keyboard(user_lang)
                )
                
        except Exception as e:
            logger.error(f"âŒ Italian help error: {e}")
            await safe_edit_text(
                msg,
                get_msg(user_lang, "error"),
                get_italian_help_keyboard(word, user_lang)
            )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û²Û¸: Ø¢Ù…Ø§Ø± Ùˆ ÙˆØ¶Ø¹ÛŒØª Ø³Ø±ÙˆÛŒØ³
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.callback_query(F.data == "ai_status")
@router.callback_query(F.data == "ai:stats")
async def show_stats(callback: CallbackQuery, state: FSMContext):
    """Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø± Ø³Ø±ÙˆÛŒØ³ AI"""
    user_id = callback.from_user.id
    user_lang = await get_user_language(user_id, state)
    
    await safe_answer_callback(callback)
    
    text_parts = [f"{get_msg(user_lang, 'stats_title')}\n\n"]
    text_parts.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n")
    
    # ÙˆØ¶Ø¹ÛŒØª Ø³Ø±ÙˆÛŒØ³
    if AI_SERVICE_AVAILABLE and ai_service:
        try:
            status = ai_service.get_status()
            status_code = status.get("status", "unknown")
            
            status_map = {
                "online": ("ğŸŸ¢", "Ø¢Ù†Ù„Ø§ÛŒÙ†"),
                "degraded": ("ğŸŸ¡", "Ù…Ø­Ø¯ÙˆØ¯"),
                "limited": ("ğŸŸ ", "Ú©Ù†Ø¯"),
                "offline": ("ğŸ”´", "Ø¢ÙÙ„Ø§ÛŒÙ†")
            }
            status_emoji, status_text = status_map.get(status_code, ("âšª", status_code))
            
            text_parts.append(f"<b>ğŸ”Œ ÙˆØ¶Ø¹ÛŒØª Ø³Ø±ÙˆÛŒØ³:</b> {status_emoji} {status_text}\n")
            text_parts.append(f"<b>ğŸ”‘ API Key:</b> {'âœ…' if status.get('api_key_configured') else 'âŒ'}\n")
            text_parts.append(f"<b>ğŸ¤– Ù…Ø¯Ù„ Ù¾ÛŒØ´â€ŒÙØ±Ø¶:</b> {status.get('default_model', 'N/A')}\n\n")
            
            # Cold/Warm
            health = await service_manager.health_check()
            cold_status = "â„ï¸ Cold" if health["is_cold"] else "ğŸ”¥ Warm"
            text_parts.append(f"<b>ğŸŒ¡ ÙˆØ¶Ø¹ÛŒØª:</b> {cold_status}\n")
            text_parts.append(f"<b>â± Ø¢Ø®Ø±ÛŒÙ† Ù¾Ø§Ø³Ø®:</b> {health['last_response_time_ms']}ms\n\n")
            
            # Ø¢Ù…Ø§Ø± Ø³Ø±ÙˆÛŒØ³
            text_parts.append(f"<b>ğŸ“ˆ Ø¢Ù…Ø§Ø± Ø³Ø±ÙˆÛŒØ³:</b>\n")
            text_parts.append(f"â€¢ Ú©Ù„: <code>{status.get('total_requests', 0)}</code>\n")
            text_parts.append(f"â€¢ Ù…ÙˆÙÙ‚: <code>{status.get('successful_requests', 0)}</code>\n")
            text_parts.append(f"â€¢ Voice: <code>{status.get('voice_requests', 0)}</code>\n")
            text_parts.append(f"â€¢ Image: <code>{status.get('image_requests', 0)}</code>\n")
            text_parts.append(f"â€¢ Ù†Ø±Ø® Ù…ÙˆÙÙ‚ÛŒØª: <code>{status.get('success_rate', '0%')}</code>\n\n")
            
            text_parts.append(f"<b>ğŸ¤– Ù…Ø¯Ù„â€ŒÙ‡Ø§:</b> {status.get('active_models', 0)}/{status.get('total_models', 0)}\n")
            text_parts.append(f"<b>ğŸ’¾ Ú©Ø´:</b> {status.get('cache_size', 0)} Ø¢ÛŒØªÙ…\n\n")
            
        except Exception as e:
            logger.error(f"âŒ Error getting status: {e}")
            text_parts.append("âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ÙˆØ¶Ø¹ÛŒØª\n\n")
    else:
        text_parts.append("ğŸ”´ <b>Ø³Ø±ÙˆÛŒØ³ AI:</b> ØºÛŒØ±ÙØ¹Ø§Ù„\n\n")
    
    # Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù‡Ù†Ø¯Ù„Ø±
    text_parts.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n")
    text_parts.append(f"<b>ğŸ“Š Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Øª:</b>\n")
    text_parts.append(f"â€¢ Ú©Ù„: <code>{metrics.total_requests}</code>\n")
    text_parts.append(f"â€¢ Ù…ÙˆÙÙ‚: <code>{metrics.successful_requests}</code>\n")
    text_parts.append(f"â€¢ Ù†Ø§Ù…ÙˆÙÙ‚: <code>{metrics.failed_requests}</code>\n")
    text_parts.append(f"â€¢ Voice: <code>{metrics.voice_requests}</code>\n")
    text_parts.append(f"â€¢ Image: <code>{metrics.image_requests}</code>\n")
    text_parts.append(f"â€¢ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡: <code>{metrics.history_used_count}</code>\n")
    text_parts.append(f"â€¢ Model Fallback: <code>{metrics.model_fallback_count}</code>\n")
    text_parts.append(f"â€¢ Ù†Ø±Ø® Ù…ÙˆÙÙ‚ÛŒØª: <code>{metrics.success_rate:.1f}%</code>\n")
    text_parts.append(f"â€¢ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø²Ù…Ø§Ù†: <code>{metrics.avg_response_time_ms:.0f}ms</code>\n")
    text_parts.append(f"â€¢ Ú©Ø§Ø±Ø¨Ø±Ø§Ù† ÛŒÚ©ØªØ§: <code>{len(metrics.requests_per_user)}</code>\n\n")
    
    # ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú†Øª
    history_stats = chat_history_manager.get_stats()
    text_parts.append(f"<b>ğŸ’¬ ØªØ§Ø±ÛŒØ®Ú†Ù‡:</b>\n")
    text_parts.append(f"â€¢ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†: <code>{history_stats['active_users']}</code>\n")
    text_parts.append(f"â€¢ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§: <code>{history_stats['total_messages']}</code>\n\n")
    
    # Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ù…ØµØ±Ù
    if metrics.requests_per_model:
        text_parts.append(f"<b>ğŸ† Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ù…ØµØ±Ù:</b>\n")
        for model, count in metrics.requests_per_model.most_common(3):
            model_info = USER_SELECTABLE_MODELS.get(model, {})
            icon = model_info.get("icon", "ğŸ¤–")
            text_parts.append(f"â€¢ {icon} {model}: {count}\n")
        text_parts.append("\n")
    
    text_parts.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n")
    text_parts.append(f"<i>â° {datetime.now().strftime('%H:%M:%S')}</i>")
    
    await safe_edit_text(
        callback.message,
        "".join(text_parts),
        get_stats_keyboard(user_id, user_lang)
    )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û²Û¹: Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ø§Ø¯Ù…ÛŒÙ†
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.callback_query(F.data == "ai:admin_clear")
async def admin_clear_cache(callback: CallbackQuery, state: FSMContext):
    """Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ú©Ø´ AI"""
    user_id = callback.from_user.id
    
    if not is_admin(user_id):
        await safe_answer_callback(callback, get_msg("fa", "no_access"), show_alert=True)
        return
    
    if AI_SERVICE_AVAILABLE and ai_service:
        try:
            count = ai_service.clear_cache()
            logger.info(f"ğŸ—‘ Admin {user_id} cleared {count} cache items")
            await safe_answer_callback(callback, f"ğŸ—‘ {count} Ø¢ÛŒØªÙ… Ù¾Ø§Ú© Ø´Ø¯!", show_alert=True)
        except Exception as e:
            await safe_answer_callback(callback, f"âŒ Ø®Ø·Ø§: {e}", show_alert=True)
    
    await show_stats(callback, state)


@router.callback_query(F.data == "ai:admin_models")
async def admin_list_models(callback: CallbackQuery, state: FSMContext):
    """Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§"""
    user_id = callback.from_user.id
    user_lang = await get_user_language(user_id, state)
    
    if not is_admin(user_id):
        await safe_answer_callback(callback, get_msg("fa", "no_access"), show_alert=True)
        return
    
    await safe_answer_callback(callback)
    
    text_parts = ["ğŸ“‹ <b>Ù„ÛŒØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ AI</b>\n\n"]
    
    if AI_SERVICE_AVAILABLE and ai_service:
        try:
            models = ai_service.get_available_models()
            
            for model in models[:15]:
                status_icon = "ğŸŸ¢" if model.get("is_active") else "ğŸ”´"
                name = model.get("name", "Unknown")
                provider = model.get("provider", "")
                requests = model.get("requests", 0)
                vision = "ğŸ–¼ï¸" if model.get("supports_vision") else ""
                audio = "ğŸ¤" if model.get("supports_audio") else ""
                
                text_parts.append(f"{status_icon} <b>{name}</b> {vision}{audio}\n")
                text_parts.append(f"   ğŸ“¡ {provider} | ğŸ“Š {requests}\n\n")
            
        except Exception as e:
            text_parts.append(f"âŒ Ø®Ø·Ø§: {e}\n")
    else:
        text_parts.append("ğŸ”´ Ø³Ø±ÙˆÛŒØ³ ØºÛŒØ±ÙØ¹Ø§Ù„\n")
    
    await safe_edit_text(
        callback.message,
        "".join(text_parts),
        get_stats_keyboard(user_id, user_lang)
    )


@router.callback_query(F.data == "ai:admin_test")
async def admin_test_service(callback: CallbackQuery, state: FSMContext):
    """ØªØ³Øª Ø³Ø±ÙˆÛŒØ³ AI"""
    user_id = callback.from_user.id
    user_lang = await get_user_language(user_id, state)
    
    if not is_admin(user_id):
        await safe_answer_callback(callback, get_msg("fa", "no_access"), show_alert=True)
        return
    
    await safe_answer_callback(callback, "â³ ØªØ³Øª...")
    await safe_edit_text(callback.message, "ğŸ”§ <b>ØªØ³Øª Ø³Ø±ÙˆÛŒØ³ AI</b>\n\nâ³ Ø¯Ø± Ø­Ø§Ù„ Ø§Ø±Ø³Ø§Ù„...")
    
    typing_task = asyncio.create_task(keep_typing(callback.bot, callback.message.chat.id))
    
    try:
        if AI_SERVICE_AVAILABLE and ai_service:
            start_time = datetime.now()
            
            response = await ai_service.chat(
                message="Test: Say 'OK' and the current time.",
                user_id=user_id,
                use_cache=False
            )
            
            elapsed_ms = int((datetime.now() - start_time).total_seconds() * 1000)
            
            if response and response.is_ai_generated:
                service_manager.record_success(elapsed_ms)
                
                text = f"âœ… <b>ØªØ³Øª Ù…ÙˆÙÙ‚!</b>\n\n"
                text += f"<b>â± Ø²Ù…Ø§Ù†:</b> {elapsed_ms}ms\n"
                text += f"<b>ğŸ¤– Ù…Ø¯Ù„:</b> {response.model_used}\n"
                text += f"<b>ğŸ“¦ Ú©Ø´:</b> {'Ø¨Ù„Ù‡' if response.from_cache else 'Ø®ÛŒØ±'}\n"
                text += f"<b>ğŸ”„ Fallback:</b> {'Ø¨Ù„Ù‡' if response.was_model_fallback else 'Ø®ÛŒØ±'}\n\n"
                text += f"<b>ğŸ“ Ù¾Ø§Ø³Ø®:</b>\n{response.text[:300]}"
            else:
                text = f"âŒ <b>ØªØ³Øª Ù†Ø§Ù…ÙˆÙÙ‚</b>\n\nâ± {elapsed_ms}ms"
        else:
            text = "ğŸ”´ <b>Ø³Ø±ÙˆÛŒØ³ ØºÛŒØ±ÙØ¹Ø§Ù„</b>"
        
    except Exception as e:
        text = f"âŒ <b>Ø®Ø·Ø§:</b>\n<code>{str(e)[:200]}</code>"
    
    finally:
        typing_task.cancel()
        with suppress(asyncio.CancelledError):
            await typing_task
    
    await safe_edit_text(callback.message, text, get_stats_keyboard(user_id, user_lang))


@router.callback_query(F.data == "ai:admin_warmup")
async def admin_warmup_service(callback: CallbackQuery, state: FSMContext):
    """Warm-up Ø¯Ø³ØªÛŒ"""
    user_id = callback.from_user.id
    user_lang = await get_user_language(user_id, state)
    
    if not is_admin(user_id):
        await safe_answer_callback(callback, get_msg("fa", "no_access"), show_alert=True)
        return
    
    await safe_answer_callback(callback, "ğŸ”¥ Warm-up...")
    await safe_edit_text(callback.message, "ğŸ”¥ <b>Warm-up</b>\n\nâ³ Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¬Ø±Ø§...")
    
    typing_task = asyncio.create_task(keep_typing(callback.bot, callback.message.chat.id))
    
    try:
        start_time = datetime.now()
        success = await service_manager.warmup(force=True)
        elapsed_ms = int((datetime.now() - start_time).total_seconds() * 1000)
        
        if success:
            metrics.record_warmup()
            health = await service_manager.health_check()
            
            text = f"âœ… <b>Warm-up Ù…ÙˆÙÙ‚!</b>\n\n"
            text += f"<b>â± Ø²Ù…Ø§Ù†:</b> {elapsed_ms}ms\n"
            text += f"<b>ğŸŒ¡ ÙˆØ¶Ø¹ÛŒØª:</b> {'ğŸ”¥ Warm' if not health['is_cold'] else 'â„ï¸ Cold'}\n"
        else:
            text = f"âŒ <b>Warm-up Ù†Ø§Ù…ÙˆÙÙ‚</b>\n\nâ± {elapsed_ms}ms"
        
    except Exception as e:
        text = f"âŒ <b>Ø®Ø·Ø§:</b>\n<code>{str(e)[:200]}</code>"
    
    finally:
        typing_task.cancel()
        with suppress(asyncio.CancelledError):
            await typing_task
    
    await safe_edit_text(callback.message, text, get_stats_keyboard(user_id, user_lang))


@router.callback_query(F.data == "ai:admin_metrics")
async def admin_show_metrics(callback: CallbackQuery, state: FSMContext):
    """Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡"""
    user_id = callback.from_user.id
    user_lang = await get_user_language(user_id, state)
    
    if not is_admin(user_id):
        await safe_answer_callback(callback, get_msg("fa", "no_access"), show_alert=True)
        return
    
    await safe_answer_callback(callback)
    
    stats = metrics.to_dict()
    
    text_parts = ["ğŸ“Š <b>Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡</b>\n\n"]
    
    for key, value in stats.items():
        text_parts.append(f"â€¢ <b>{key}:</b> <code>{value}</code>\n")
    
    text_parts.append(f"\n<b>ğŸ† Ú©Ø§Ø±Ø¨Ø±Ø§Ù† Ù¾Ø±Ù…ØµØ±Ù:</b>\n")
    for uid, count in metrics.requests_per_user.most_common(5):
        text_parts.append(f"â€¢ {uid}: {count}\n")
    
    text_parts.append(f"\n<b>âŒ Ø®Ø·Ø§Ù‡Ø§:</b>\n")
    for error, count in metrics.errors_by_type.most_common(5):
        text_parts.append(f"â€¢ {error}: {count}\n")
    
    await safe_edit_text(
        callback.message,
        "".join(text_parts),
        get_stats_keyboard(user_id, user_lang)
    )


@router.callback_query(F.data == "ai:admin_reset_metrics")
async def admin_reset_metrics(callback: CallbackQuery, state: FSMContext):
    """Ø±ÛŒØ³Øª Ø¢Ù…Ø§Ø±"""
    user_id = callback.from_user.id
    
    if not is_admin(user_id):
        await safe_answer_callback(callback, get_msg("fa", "no_access"), show_alert=True)
        return
    
    old_stats = metrics.reset()
    
    logger.info(f"ğŸ“Š Admin {user_id} reset metrics")
    
    await safe_answer_callback(
        callback,
        f"ğŸ”„ Ø±ÛŒØ³Øª Ø´Ø¯! (Ù‚Ø¨Ù„ÛŒ: {old_stats.get('total_requests', 0)} Ø¯Ø±Ø®ÙˆØ§Ø³Øª)",
        show_alert=True
    )
    
    await show_stats(callback, state)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û³Û°: Ø¯Ø³ØªÙˆØ±Ø§Øª Ø¯ÛŒØ¨Ø§Ú¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.message(Command("ai_debug"))
async def debug_ai(message: Message, state: FSMContext):
    """Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯ÛŒØ¨Ø§Ú¯"""
    user_id = message.from_user.id
    
    if not is_admin(user_id):
        return
    
    current_state = await state.get_state()
    state_data = await state.get_data()
    
    text_parts = ["ğŸ” <b>Debug Info</b>\n\n"]
    
    text_parts.append(f"<b>ğŸ”„ State:</b> <code>{current_state}</code>\n")
    text_parts.append(f"<b>ğŸ“¦ Data:</b> <code>{list(state_data.keys())}</code>\n\n")
    
    text_parts.append(f"<b>ğŸ¤– Services:</b>\n")
    text_parts.append(f"â€¢ AI: <code>{AI_SERVICE_AVAILABLE}</code>\n")
    text_parts.append(f"â€¢ Lang: <code>{LANG_SERVICE_AVAILABLE}</code>\n")
    text_parts.append(f"â€¢ DB: <code>{DATABASE_AVAILABLE}</code>\n\n")
    
    health = await service_manager.health_check()
    text_parts.append(f"<b>ğŸŒ¡ Service Manager:</b>\n")
    for key, value in health.items():
        text_parts.append(f"â€¢ {key}: <code>{value}</code>\n")
    
    text_parts.append(f"\n<b>âš™ï¸ Config:</b>\n")
    text_parts.append(f"â€¢ Voice: <code>{VOICE_ENABLED}</code>\n")
    text_parts.append(f"â€¢ Image: <code>{IMAGE_ENABLED}</code>\n")
    text_parts.append(f"â€¢ History: <code>{HISTORY_ENABLED}</code>\n")
    text_parts.append(f"â€¢ Default Model: <code>{DEFAULT_MODEL}</code>\n")
    
    user_model = get_user_model(user_id)
    text_parts.append(f"\n<b>ğŸ‘¤ Your Model:</b> <code>{user_model}</code>\n")
    
    history = await chat_history_manager.get(user_id)
    text_parts.append(f"<b>ğŸ’¬ Your History:</b> <code>{len(history)} messages</code>\n")
    
    await message.answer("".join(text_parts), parse_mode=ParseMode.HTML)


@router.message(Command("ai_cleanup"))
async def manual_cleanup(message: Message):
    """Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø¯Ø³ØªÛŒ"""
    user_id = message.from_user.id
    
    if not is_admin(user_id):
        return
    
    await message.answer("ğŸ§¹ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ...")
    
    history_cleaned = await chat_history_manager.cleanup_old_data()
    rate_cleaned = await rate_limiter.cleanup()
    model_cleaned = cleanup_user_model_preferences()
    
    await message.answer(
        f"âœ… <b>Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯</b>\n\n"
        f"â€¢ ØªØ§Ø±ÛŒØ®Ú†Ù‡: {history_cleaned} Ú©Ø§Ø±Ø¨Ø±\n"
        f"â€¢ Rate Limit: {rate_cleaned} ÙˆØ±ÙˆØ¯ÛŒ\n"
        f"â€¢ Model Prefs: {model_cleaned} Ú©Ø§Ø±Ø¨Ø±",
        parse_mode=ParseMode.HTML
    )


@router.message(Command("ai_model"))
async def set_model_command(message: Message):
    """ØªÙ†Ø¸ÛŒÙ… Ù…Ø¯Ù„ Ø¨Ø§ Ø¯Ø³ØªÙˆØ±"""
    user_id = message.from_user.id
    
    text = message.text or ""
    parts = text.split()
    
    if len(parts) < 2:
        models_text = "\n".join([
            f"â€¢ <code>{key}</code> - {info['name']}"
            for key, info in USER_SELECTABLE_MODELS.items()
        ])
        await message.answer(
            f"ğŸ“ <b>Ø§Ø³ØªÙØ§Ø¯Ù‡:</b>\n/ai_model MODEL_KEY\n\n<b>Ù…Ø¯Ù„â€ŒÙ‡Ø§:</b>\n{models_text}",
            parse_mode=ParseMode.HTML
        )
        return
    
    model_key = parts[1].lower()
    
    if set_user_model(user_id, model_key):
        model_info = USER_SELECTABLE_MODELS.get(model_key, {})
        await message.answer(
            f"âœ… Ù…Ø¯Ù„ <b>{model_info.get('name', model_key)}</b> Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯.",
            parse_mode=ParseMode.HTML
        )
    else:
        await message.answer("âŒ Ù…Ø¯Ù„ ÛŒØ§ÙØª Ù†Ø´Ø¯.")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û³Û±: Ø¨Ø§Ø²Ø®ÙˆØ±Ø¯ Ùˆ Ù„ØºÙˆ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.callback_query(F.data.startswith("ai:feedback_"))
async def handle_feedback(callback: CallbackQuery, state: FSMContext):
    """Ø¯Ø±ÛŒØ§ÙØª Ø¨Ø§Ø²Ø®ÙˆØ±Ø¯"""
    user_id = callback.from_user.id
    feedback_type = callback.data.replace("ai:feedback_", "")
    
    logger.info(f"ğŸ“ Feedback from {user_id}: {feedback_type}")
    
    if feedback_type == "good":
        await safe_answer_callback(callback, "ğŸ™ Ù…Ù…Ù†ÙˆÙ†!", show_alert=True)
    else:
        await safe_answer_callback(callback, "ğŸ™ Ù…Ù…Ù†ÙˆÙ†! Ø³Ø¹ÛŒ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ø¨Ù‡ØªØ± Ø¨Ø´ÛŒÙ….", show_alert=True)


@router.message(Command("cancel"), StateFilter(AIStates))
async def cancel_command(message: Message, state: FSMContext):
    """Ù„ØºÙˆ Ø¹Ù…Ù„ÛŒØ§Øª"""
    user_id = message.from_user.id
    user_lang = await get_user_language(user_id, state)
    
    await state.clear()
    
    await message.answer(
        get_msg(user_lang, "cancelled"),
        reply_markup=get_back_keyboard(user_lang),
        parse_mode=ParseMode.HTML
    )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û³Û²: ØªØ³Ú©â€ŒÙ‡Ø§ÛŒ Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_cleanup_task: Optional[asyncio.Task] = None


async def cleanup_loop():
    """Ø­Ù„Ù‚Ù‡ Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø±"""
    logger.info("ğŸ§¹ Cleanup loop started")
    
    while True:
        try:
            await asyncio.sleep(HISTORY_CLEANUP_INTERVAL)
            
            logger.info("ğŸ§¹ Running scheduled cleanup...")
            
            history_cleaned = await chat_history_manager.cleanup_old_data()
            rate_cleaned = await rate_limiter.cleanup()
            model_cleaned = cleanup_user_model_preferences()
            
            if AI_SERVICE_AVAILABLE and ai_service:
                try:
                    ai_service.save_stats()
                except Exception:
                    pass
            
            logger.info(f"ğŸ§¹ Cleanup: history={history_cleaned}, rate={rate_cleaned}, models={model_cleaned}")
            
        except asyncio.CancelledError:
            logger.info("ğŸ§¹ Cleanup loop cancelled")
            break
        except Exception as e:
            logger.error(f"âŒ Cleanup error: {e}")
            await asyncio.sleep(60)


def start_cleanup_task() -> asyncio.Task:
    """Ø´Ø±ÙˆØ¹ ØªØ³Ú© Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ"""
    global _cleanup_task
    
    if _cleanup_task is None or _cleanup_task.done():
        _cleanup_task = asyncio.create_task(cleanup_loop())
    
    return _cleanup_task


def stop_cleanup_task() -> None:
    """ØªÙˆÙ‚Ù ØªØ³Ú© Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ"""
    global _cleanup_task
    
    if _cleanup_task and not _cleanup_task.done():
        _cleanup_task.cancel()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û³Û³: Ù‡ÙˆÚ©â€ŒÙ‡Ø§ÛŒ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ùˆ ØªÙˆÙ‚Ù
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def on_startup() -> None:
    """
    Ø§Ø¬Ø±Ø§ Ø¯Ø± Ø²Ù…Ø§Ù† Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø¨Ø§Øª
    
    Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø¨Ø§ÛŒØ¯ Ø§Ø² main.py ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ø´ÙˆØ¯:
        from handlers.ai_handler import on_startup
        await on_startup()
    """
    logger.info("ğŸš€ AI Handler starting up...")
    
    # Ø´Ø±ÙˆØ¹ ØªØ³Ú© Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ
    start_cleanup_task()
    
    # Ø´Ø±ÙˆØ¹ Keep-Alive
    if KEEP_ALIVE_ENABLED:
        await service_manager.start_keep_alive()
    
    # Warm-up Ø§ÙˆÙ„ÛŒÙ‡
    if WARMUP_ENABLED and AI_SERVICE_AVAILABLE:
        logger.info("ğŸ”¥ Performing initial warmup...")
        try:
            success = await service_manager.warmup(force=True)
            if success:
                metrics.record_warmup()
                logger.success("âœ… Initial warmup successful")
            else:
                logger.warning("âš ï¸ Initial warmup failed")
        except Exception as e:
            logger.error(f"âŒ Warmup error: {e}")
    
    # Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø±ÙˆÛŒØ³
    if AI_SERVICE_AVAILABLE and ai_service:
        try:
            status = ai_service.get_status()
            logger.info(f"ğŸ¤– AI Service: {status.get('status', 'unknown')}")
            logger.info(f"ğŸ¤– Models: {status.get('active_models', 0)}")
        except Exception as e:
            logger.warning(f"âš ï¸ Could not check AI: {e}")
    
    logger.success("âœ… AI Handler started")


async def on_shutdown() -> None:
    """
    Ø§Ø¬Ø±Ø§ Ø¯Ø± Ø²Ù…Ø§Ù† ØªÙˆÙ‚Ù Ø¨Ø§Øª
    
    Ø§ÛŒÙ† ØªØ§Ø¨Ø¹ Ø¨Ø§ÛŒØ¯ Ø§Ø² main.py ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ø´ÙˆØ¯:
        from handlers.ai_handler import on_shutdown
        await on_shutdown()
    """
    logger.info("ğŸ›‘ AI Handler shutting down...")
    
    stop_cleanup_task()
    
    await service_manager.stop_keep_alive()
    
    if AI_SERVICE_AVAILABLE and ai_service:
        try:
            ai_service.save_stats()
        except Exception:
            pass
    
    logger.info(f"ğŸ“Š Final metrics: {metrics.to_dict()}")
    
    logger.success("âœ… AI Handler stopped")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û³Û´: ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø«Ø¨Øª Ø±ÙˆØªØ±
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def setup_router(parent_router) -> Router:
    """Ø«Ø¨Øª Ø±ÙˆØªØ± AI Ø¯Ø± Ø±ÙˆØªØ± Ø§ØµÙ„ÛŒ"""
    parent_router.include_router(router)
    logger.info("ğŸ“ AI Router registered")
    return router


def get_router() -> Router:
    """Ø¯Ø±ÛŒØ§ÙØª Ø±ÙˆØªØ± AI"""
    return router


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø®Ø´ Û³Ûµ: Ù„Ø§Ú¯ Ù†Ù‡Ø§ÛŒÛŒ Ùˆ Export
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

logger.success("â•" * 60)
logger.success("ğŸ¤– AI Handler v7.0 - Fully Loaded!")
logger.success("â•" * 60)
logger.info(f"   ğŸ“¦ Router: {router.name}")
logger.info(f"   ğŸ¤– AI Service: {'âœ…' if AI_SERVICE_AVAILABLE else 'âŒ'}")
logger.info(f"   ğŸŒ Lang Service: {'âœ…' if LANG_SERVICE_AVAILABLE else 'âŒ'}")
logger.info(f"   ğŸ’¾ Database: {'âœ…' if DATABASE_AVAILABLE else 'âŒ'}")
logger.info(f"   ğŸ¤ Voice: {'âœ…' if VOICE_ENABLED else 'âŒ'}")
logger.info(f"   ğŸ–¼ï¸ Image: {'âœ…' if IMAGE_ENABLED else 'âŒ'}")
logger.info(f"   ğŸ’¬ History: {'âœ…' if HISTORY_ENABLED else 'âŒ'}")
logger.info(f"   ğŸ”¥ Warmup: {'âœ…' if WARMUP_ENABLED else 'âŒ'}")
logger.info(f"   ğŸ’“ Keep-Alive: {'âœ…' if KEEP_ALIVE_ENABLED else 'âŒ'}")
logger.info(f"   ğŸ¤– Default Model: {DEFAULT_MODEL}")
logger.info(f"   ğŸ“Š Models Available: {len(USER_SELECTABLE_MODELS)}")
logger.success("â•" * 60)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Export
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

__all__ = [
    # Router
    "router",
    "get_router",
    "setup_router",
    
    # States
    "AIStates",
    
    # Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§
    "AIMetrics",
    "ChatHistoryManager",
    "RateLimiter",
    "AIServiceManager",
    "ServiceHealth",
    
    # Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø±Ø§Ø³Ø±ÛŒ
    "metrics",
    "chat_history_manager",
    "rate_limiter",
    "service_manager",
    
    # ØªÙˆØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ
    "chat_with_history",
    
    # ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ
    "safe_answer",
    "safe_edit_text",
    "safe_delete_message",
    "safe_answer_callback",
    "keep_typing",
    "get_user_language",
    "is_admin",
    "get_user_model",
    "set_user_model",
    
    # Context Managers
    "ai_processing_context",
    "callback_processing_context",
    
    # ÙØ±Ù…Øªâ€ŒØ¯Ù‡ÛŒ
    "format_ai_response",
    "format_translation_response",
    "format_italian_help_response",
    "create_error_response",
    
    # Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§
    "get_msg",
    "get_random_emoji",
    "MESSAGES",
    
    # Ú©ÛŒØ¨ÙˆØ±Ø¯Ù‡Ø§
    "get_ai_menu_keyboard",
    "get_chat_keyboard",
    "get_chat_with_model_keyboard",
    "get_translate_menu_keyboard",
    "get_translation_result_keyboard",
    "get_italian_help_keyboard",
    "get_quick_questions_keyboard",
    "get_back_keyboard",
    "get_cancel_keyboard",
    "get_stats_keyboard",
    "get_model_selection_keyboard",
    "get_voice_result_keyboard",
    "get_image_result_keyboard",
    
    # Ù‡ÙˆÚ©â€ŒÙ‡Ø§
    "on_startup",
    "on_shutdown",
    
    # ØªØ³Ú©â€ŒÙ‡Ø§
    "start_cleanup_task",
    "stop_cleanup_task",
    
    # Ø«Ø§Ø¨Øªâ€ŒÙ‡Ø§
    "AI_SERVICE_AVAILABLE",
    "LANG_SERVICE_AVAILABLE",
    "DATABASE_AVAILABLE",
    "VOICE_ENABLED",
    "IMAGE_ENABLED",
    "HISTORY_ENABLED",
    "WARMUP_ENABLED",
    "KEEP_ALIVE_ENABLED",
    "DEFAULT_MODEL",
    "USER_SELECTABLE_MODELS",
    "QUICK_QUESTIONS",
]